{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJnCZrWBTN9g"
      },
      "source": [
        "## Tokenization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X02C8PP2TN9h"
      },
      "source": [
        "For transformers, a fundamental step is to convert the input text into a sequence of tokens. Tokenizers are used for this purpose. Different tokenization techniques can be used (e.g., Byte-Pair Encoding).\n",
        "\n",
        "These tokenizers need to be trained on some corpus (e.g., to figure out what the most common words are). However, the Hugging Face library provides pre-trained tokenizers that can be used out of the box.\n",
        "\n",
        "Generally, each model has its own tokenizer. For example, the `BertTokenizer` is used for BERT models, and the `GPT2Tokenizer` is used for GPT-2 models.\n",
        "\n",
        "\n",
        "Since we will be using T5 for this exercise, we should be using the `T5Tokenizer` class. However, HuggingFace provides a common `AutoTokenizer` class that can be used to load the appropriate tokenizer for a given model  (do note, however, that the returned class will be the \"correct\" one!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255,
          "referenced_widgets": [
            "bc7f6fa919404acdb6df08cbbb57aeaa",
            "0f90a2b7c6a844b08b82608b3b0d19c0",
            "7a35bb9a54cb44e0979aa09f7b610f86",
            "59c3309206954e7c8389ef22ea2dd4b1",
            "f7cdc6b2ff124bb2a4b11f02da836bce",
            "822b6a3fe202462dad1f8ef02696ff71",
            "8bece923e434440cb3896c51a89973c7",
            "91f3e33f932e44febf8bcf9c335dc467",
            "630d350b72134608985be5f3d3090f69",
            "40f632aa04ea4edb942f19fc6861507e",
            "1683c3c630bb4cfcbbb0c4a60be9805a",
            "d9c2da5446c04ce7978401417be17f06",
            "f8cc9faef4e04b5082e8660198430dfa",
            "91bc44d0b62f4d29ba409d08cfa1a063",
            "10f39b471e7141ebaa9f0504a2db7868",
            "acf6b63384ee403aa82600df52985ea8",
            "3310a78d3b224b60b1a6b23f3e8eef13",
            "2eac061630094aeba3c3fa39ca1dc843",
            "f5d7045ebd3d471d801abbf9aded78c2",
            "6698d68321c04d4f92eec10776fc5446",
            "22259431bbf34057952b152cf4888817",
            "e7dc3a24ac0b4470a93783a736b9f15a",
            "8470f8c87ec446c2a1ec2d9479715396",
            "76d651c4a3a54a91a2d78e3798e5b2ee",
            "2adad6653a954973a7ca80cf80943c31",
            "1a9ccea166cb4aa0bf51a9426c3cac28",
            "291c5b112577479c8c0aa12c7fcf065d",
            "80a9232c8f2e4618b25cad1445dfdc70",
            "f7fba1b83e2842f2b2e2074687aead4e",
            "17c1be419e764c8bbb375c139cbd5be4",
            "4d9f2fe4958b486c9c83518eaa4b2f75",
            "e71a6e547fc54b0b83955c3c2f27b45b",
            "0ca1c035812c49f3aa90f3ef8cd309e2"
          ]
        },
        "id": "f4YuXh-OTN9h",
        "outputId": "e4065a18-2013-48fb-888e-69f7e8fde689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc7f6fa919404acdb6df08cbbb57aeaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9c2da5446c04ce7978401417be17f06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8470f8c87ec446c2a1ec2d9479715396"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.t5.tokenization_t5_fast.T5TokenizerFast'>\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"google-t5/t5-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# TODO: print the type of the tokenizer\n",
        "print(type(tokenizer))\n",
        "\n",
        "# This is simply converting text to tokens and tokens to text back"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmN-MrVGTN9i"
      },
      "source": [
        "### Encoding/Decoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAhnZnwjTN9i"
      },
      "source": [
        "Tokenization can be carried out by passing a string that we want to tokenize. The tokenizer implements the `__call__` method, so we can call the tokenizer directly, as follows.\n",
        "\n",
        "Note that the output is a dictionary, which generally has the following keys:\n",
        "\n",
        "- `input_ids`: The tokenized input text (a list of token IDs by default).\n",
        "- `attention_mask`: A mask that indicates which elements in the input text are tokens and which are padding tokens. For now, we can ignore this (there is no padding). It will instead become useful when we encode batches of sentences of different lengths at the same time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsNEe8IRTN9i",
        "outputId": "50b253ab-7205-4334-c6e3-88dcf6bd3bbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [21820, 6, 48, 19, 3, 9, 7142, 55, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "sentence = \"hello, this is a sentence!\"\n",
        "\n",
        "# TODO: use the tokenizer to tokenize the sentence and print the result\n",
        "tokens = tokenizer(sentence)\n",
        "print(tokens) # embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO771W6PTN9i"
      },
      "source": [
        "We can reverse the encoding operation (i.e., going from token IDs to strings) by using the `decode` method of the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vEAu3ijxTN9i",
        "outputId": "d7baea61-2a53-4c7c-d0b4-bb31f0b4eeef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello, this is a sentence!</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "tokenizer.decode(tokens[\"input_ids\"])\n",
        "# text mapped back"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHwHa_ZlTN9i"
      },
      "source": [
        "Note that we have an extra part at the end of the string, which is the special token `</s>`. This token is used to indicate the end of the input text (EOS). This token is automatically added by the tokenizer when encoding the input text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we6ATYg_TN9i"
      },
      "source": [
        "To learn what the mapping between tokens and token IDs is, we can get the tokenizer's vocabulary (`.get_vocab()`), which provides the mapping between tokens and respective IDs.\n",
        "\n",
        "For convenience, we build also a reverse vocabulary (i.e., from IDs to tokens)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ediKHFHMTN9i"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "vocabulary = tokenizer.get_vocab()\n",
        "\n",
        "# TODO: print 10 random words from the vocabulary\n",
        "reverse_vocab = { v:k for k,v in vocabulary.items() }\n",
        "\n",
        "vocab_keys = list(vocabulary.keys())\n",
        "random.shuffle(vocab_keys)\n",
        "\n",
        "# ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ya-WTe8TN9i",
        "outputId": "6e459d93-d270-4f2f-aecd-c90ac3edd29f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total vocabulary size: 32100\n"
          ]
        }
      ],
      "source": [
        "print(\"Total vocabulary size:\", len(vocabulary))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbTJ2jL1TN9j"
      },
      "source": [
        "We have a total of 32100. For T5, that's 32000 tokens + 100 special tokens (<extra_id_0>, <extra_id_1>, ..., <extra_id_99>) -- used for the tasks that T5 was trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "066ag7wuTN9j"
      },
      "source": [
        "Let's see what the token id for the special token `</s>` is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGLRhcCNTN9j",
        "outputId": "6feb5564-251b-4a72-f9c8-b8b110779bf7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "vocabulary[\"</s>\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOIzRZfzTN9j"
      },
      "source": [
        "And indeed, note that our `tokens` has a 1 showing up at the end!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXLPCBNeTN9j",
        "outputId": "abbe57bd-a3c1-47c5-d9bd-8c20a8558ec9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[21820, 6, 48, 19, 3, 9, 7142, 55, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "tokens[\"input_ids\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z9Y8EKmTN9j"
      },
      "source": [
        "We can include special tokens inside of the strings themselves. For instance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYtHZC35TN9j",
        "outputId": "70b24a97-a1cf-468d-aa70-800109ad3a1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [21820, 55, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tokenizer(\"hello!</s></s>\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW8xr03OTN9j"
      },
      "source": [
        "Here, we have 2 `</s>` tokens (the ones we specified), plus an additional one that was added by the tokenizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "It_7JSm8TN9j"
      },
      "source": [
        "Instead of getting token IDs directly, we may look at the tokens being produced, directly. We use the `tokenize()` method in this case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WygRhVaTN9j",
        "outputId": "e419af32-9b70-4f55-ea33-72c9a3ad7f98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁hello', ',', '▁this', '▁is', '▁', 'a', '▁sentence', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "tokenizer.tokenize(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUmerXtmTN9j"
      },
      "source": [
        "What's up with those `_`? They simply represent words that are starting after spaces. This helps us understand whether a token is being used at the beginning of a sentence, or if it's in the middle of a word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAQX6y2FTN9j",
        "outputId": "5cf45270-3eaf-48bd-8bf8-fcd7df85b8b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁hello', '▁', ',', 'world']\n",
            "['▁hello', '▁', ',', '▁world']\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.tokenize(\"hello    ,world\"))\n",
        "print(tokenizer.tokenize(\"hello    , world\"))\n",
        "\n",
        "# any extra space is not considered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i75YFtN9TN9k"
      },
      "source": [
        "In the above case, `_hello` is the token for the word \"hello\" at the beginning of the sentence. However, the word \"world\" is mapped to two different tokens, depending on whether there is a space before the word or not.\n",
        "\n",
        "Notice also how multiple spaces are compacted into a single one!\n",
        "\n",
        "These are all tokenizer-specific details. The tokenizer is responsible for deciding how to tokenize the input text. You may observe different behaviors for different tokenizers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy1YThAiTN9k"
      },
      "source": [
        "### Special tokens\n",
        "\n",
        "Each model typically has its own special tokens. Some are necessary for the training process, while others can be beneficial at inference time.\n",
        "\n",
        "Special attributes are available in the tokenizer class to access these special tokens. Some examples are:\n",
        "\n",
        "- `pad_token` is the token used for padding (as discussed later),\n",
        "- `bos_token` and `eos_token` tokens are used to indicate the beginning and end of the input text, respectively,\n",
        "- `mask_token` is used for masking tokens during training (e.g., for the masked LM task, with BERT),\n",
        "- `sep_token` is used to separate sentences in the input text (e.g., next sentence prediction, with BERT),\n",
        "- `cls_token` is used to indicate the beginning of the input text (e.g., for classification tasks, with BERT),\n",
        "- `unk_token` is used to indicate unknown tokens (i.e., tokens that are not in the vocabulary).\n",
        "\n",
        "Of course, not all tokenizers will use all tokens. So those attributes will be set to None, if not used.\n",
        "\n",
        "For instance, T5 has EOS and PAD tokens, but no BOS token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3JS8iTGTN9k",
        "outputId": "a8cbffc6-b738-411e-f94b-74d99957e836"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('</s>', '<pad>', None)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "tokenizer.eos_token, tokenizer.pad_token, tokenizer.bos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqmaCaMXTN9k"
      },
      "source": [
        "The `_id` suffix is used to indicate the corresponding token ID (None if not applicable)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv24cmGPTN9k",
        "outputId": "65278a8e-59e4-4924-cf2b-45db88e9ba15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 0, None)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tokenizer.eos_token_id, tokenizer.pad_token_id, tokenizer.bos_token_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7zBbEW0TN9k"
      },
      "source": [
        "### Batch encoding/decoding\n",
        "\n",
        "In general (especially at training time) we will want to encode multiple sentences at once (e.g., an entire batch of sentences).\n",
        "\n",
        "We can pass a list of sentences to be encoded to the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap_OivBoTN9k",
        "outputId": "102e108d-27be-43ad-8fc6-4eaf5e7a805f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[48, 19, 8, 166, 7142, 1]\n",
            "[1446, 6, 48, 19, 8, 511, 5932, 55, 1]\n"
          ]
        }
      ],
      "source": [
        "sentences = [\n",
        "    \"this is the first sentence\",\n",
        "    \"instead, this is the second sequence!\"\n",
        "]\n",
        "\n",
        "#TODO: use the tokenizer to tokenize the sentences and print the result\n",
        "tokens = tokenizer(sentences)\n",
        "for tok in tokens[\"input_ids\"]:\n",
        "  print(tok)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb2eDxOfTN9k"
      },
      "source": [
        "Of course, sentences of different lengths have a different number of tokens! However, tensors (that will be used by the model) need to have the same number of elements along each dimension.\n",
        "\n",
        "To do this, we can use padding: all sentences will be padded to the length of the longest sentence in the batch. This is done by adding `pad` tokens (`<pad>`, for T5).\n",
        "\n",
        "However, since the pad tokens are not part of the input text, we need to let the model know that it should not pay attention to them. That's what the `attention_mask` is for!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzcTvv3iTN9k",
        "outputId": "2e2bb43e-8d38-4182-ead7-1e83c37bd494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[48, 19, 8, 166, 7142, 1, 0, 0, 0] [1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
            "[1446, 6, 48, 19, 8, 511, 5932, 55, 1] [1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "#TODO: use the tokenizer to tokenize the sentences with padding and print the result (use padding=True)\n",
        "tokens = tokenizer(sentences, padding=True)\n",
        "for tok, att in zip(tokens[\"input_ids\"], tokens[\"attention_mask\"]):\n",
        "  print(tok, att)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u97Il_eTN9k"
      },
      "source": [
        "The first sentence is padded to the same length as the second sentence, with 0's (remember, the ID for `<pad>`!).\n",
        "\n",
        "The attention mask for the first sentence also contains 0's for the padding tokens: the model will ignore them when processing the input text.\n",
        "\n",
        "Since now all sentences have the same length, we can stack them into a single tensor. Luckily, the tokenizer can already do this for us, we just need to ask.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8gzBUPiTN9k",
        "outputId": "2a8be901-9ead-48ca-f520-45415ec2292b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  48,   19,    8,  166, 7142,    1,    0,    0,    0],\n",
            "        [1446,    6,   48,   19,    8,  511, 5932,   55,    1]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ],
      "source": [
        "#TODO: use the tokenizer to tokenize the sentences with padding as a tensor and print the result (use padding=True and return_tensors=\"pt\")\n",
        "tokens = tokenizer(sentences, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "print(tokens[\"input_ids\"])\n",
        "print(tokens[\"attention_mask\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7dDoRdnTN9k"
      },
      "source": [
        "For completeness, we can also decode batches of sentences, with `tokenizer.batch_decode()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIc7Qp_0TN9k",
        "outputId": "24521ec1-f5bf-45db-f55e-f5cc52ab802d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this is the first sentence</s><pad><pad><pad>',\n",
              " 'instead, this is the second sequence!</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tokenizer.batch_decode(tokens[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lts2TT1WTN9l"
      },
      "source": [
        "## Model analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpI7ytyKTN9l"
      },
      "source": [
        "Now we can go ahead and finally load our T5 model. We once again use a pretrained version available on HuggingFace.\n",
        "\n",
        "In general, we could use the `AutoModel` class for the loading, of the model. However, that version of the model does not include the specific heads for the tasks that T5 was trained on.\n",
        "\n",
        "The transformers library can make our life easier by defining a family of `AutoModel...` classes.\n",
        "\n",
        "For instance, the following are some commonly adopted classes:\n",
        "- `AutoModel`: the base class for all models,\n",
        "- `AutoModelForSequenceClassification`: a model for sequence classification tasks. It consists of a base model plus a classification head (linear layer + softmax). Note that, generally, the classification head is initialized randomly, and it needs to be trained on the specific task (but the library will let you know with a warning),\n",
        "- `AutoModelForCaualLM`: a model for causal language modeling tasks (e.g., GPT-2), where we generate the output tokens one by one,\n",
        "- `AutoModelForMaskedLM`: a model for masked language modeling tasks (e.g., BERT), where we predict the masked tokens in the input text,\n",
        "- `AutoModelForTokenClassification`: a model for token classification tasks (e.g., NER), where we classify each token in the input text.\n",
        "- `AutoModelForSeq2SeqLM`: a model for sequence-to-sequence tasks (e.g., T5), where we generate the output tokens one by one in an autoregressive manner, conditioned on the input sequence.\n",
        "\n",
        "In our specific case, we will use the `AutoModelForSeq2SeqLM` class to be able to generate new tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "208c94eade1644a582bae703aabb495c",
            "842815ea79ec4847bea59057d6cc7b21",
            "2c15b72eb6ec4f0897035d26c181444f",
            "ea3ef4d9226d43de8b9cd512ebf06052",
            "3dca8268bace4c979359c1a2395e50ee",
            "294f84fb905448f794fbc131f73b7b81",
            "ca9057bee3784791805d0ee672bf34e9",
            "110ca3d1e02d4ec2ab38d47e8d8ef900",
            "9ffc8d765a6c443fbaa9cae3c35f4758",
            "095bf3c65274404bb1b5c7d9d565a6ac",
            "edae78ee811b41c8a3f44c5c333dfe7d",
            "820449386d43425e952aa6094e4fff65",
            "80e544ae95184e6aba8430f608d35f4a",
            "c0976e1d10ac4328a28e85da7f319de2",
            "a3b865f448254fedad2f1c08f4038ae5",
            "7897df3dfd014af782e6cc591f9cd8c0",
            "514285525d0b4f52924f9cbf06f6ef9f",
            "f8f9c711447447e8b13061be50bf4cbe",
            "781c5f6eac144774a3edf2072b796031",
            "7e58dc0cce434e638a835430ed47cf12",
            "48d363794e9a45ceb8d6fa5fe1a2cdaf",
            "b41daeebbb7546c6986db5ceb7ed3fe5"
          ]
        },
        "id": "09V8Pz2ETN9n",
        "outputId": "ac082e44-e8b4-49c6-9691-aaac0248d6a0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "208c94eade1644a582bae703aabb495c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "820449386d43425e952aa6094e4fff65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.t5.modeling_t5.T5ForConditionalGeneration'>\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "# import from the transformer library\n",
        "# the model name is exaclty the same passed before for the tokenizer\n",
        "\n",
        "# TODO: print the type of the model\n",
        "print(type(model))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtudZelSTN9n"
      },
      "source": [
        "To better understand the model, we can take a look at the model's configuration. The configuration contains all the hyperparameters of the model. The configuration is available as a dictionary, and we can access the values by using the attribute notation.\n",
        "\n",
        "You can find the model's configuration object in the `config` attribute of the model. Or, if you only need the configuration, you can directly load it using the `AutoConfig` class.\n",
        "\n",
        "```python\n",
        "from transformers import AutoConfig\n",
        "\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saATU4rFTN9n",
        "outputId": "a3c04b4f-20a9-4c2f-fe55-db8d81230b4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5Config {\n",
              "  \"architectures\": [\n",
              "    \"T5ForConditionalGeneration\"\n",
              "  ],\n",
              "  \"classifier_dropout\": 0.0,\n",
              "  \"d_ff\": 3072,\n",
              "  \"d_kv\": 64,\n",
              "  \"d_model\": 768,\n",
              "  \"decoder_start_token_id\": 0,\n",
              "  \"dense_act_fn\": \"relu\",\n",
              "  \"dropout_rate\": 0.1,\n",
              "  \"dtype\": \"float32\",\n",
              "  \"eos_token_id\": 1,\n",
              "  \"feed_forward_proj\": \"relu\",\n",
              "  \"initializer_factor\": 1.0,\n",
              "  \"is_encoder_decoder\": true,\n",
              "  \"is_gated_act\": false,\n",
              "  \"layer_norm_epsilon\": 1e-06,\n",
              "  \"model_type\": \"t5\",\n",
              "  \"n_positions\": 512,\n",
              "  \"num_decoder_layers\": 12,\n",
              "  \"num_heads\": 12,\n",
              "  \"num_layers\": 12,\n",
              "  \"output_past\": true,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"relative_attention_max_distance\": 128,\n",
              "  \"relative_attention_num_buckets\": 32,\n",
              "  \"task_specific_params\": {\n",
              "    \"summarization\": {\n",
              "      \"early_stopping\": true,\n",
              "      \"length_penalty\": 2.0,\n",
              "      \"max_length\": 200,\n",
              "      \"min_length\": 30,\n",
              "      \"no_repeat_ngram_size\": 3,\n",
              "      \"num_beams\": 4,\n",
              "      \"prefix\": \"summarize: \"\n",
              "    },\n",
              "    \"translation_en_to_de\": {\n",
              "      \"early_stopping\": true,\n",
              "      \"max_length\": 300,\n",
              "      \"num_beams\": 4,\n",
              "      \"prefix\": \"translate English to German: \"\n",
              "    },\n",
              "    \"translation_en_to_fr\": {\n",
              "      \"early_stopping\": true,\n",
              "      \"max_length\": 300,\n",
              "      \"num_beams\": 4,\n",
              "      \"prefix\": \"translate English to French: \"\n",
              "    },\n",
              "    \"translation_en_to_ro\": {\n",
              "      \"early_stopping\": true,\n",
              "      \"max_length\": 300,\n",
              "      \"num_beams\": 4,\n",
              "      \"prefix\": \"translate English to Romanian: \"\n",
              "    }\n",
              "  },\n",
              "  \"transformers_version\": \"4.57.0\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 32128\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "model.config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnHZ4GWrTN9n"
      },
      "source": [
        "Lots of information going on here. We can just take a few key aspects:\n",
        "\n",
        "- `d_kv` = 64. This is the dimension of keys $d_k$ (so also queries) and values $d_v$ in the attention mechanism. It is common, to keep things simple, to use the same number of dimensions for keys, queries, and values (even though this is not strictly necessary).\n",
        "- `d_model` = 768. This is the dimension of the output of each transformer block.\n",
        "- `d_ff` = 3072. This is the dimension of the feedforward network in each transformer block. We will see that the feedforward network is composed of two linear layers with a ReLU activation in between (`d_model -> d_ff -> d_model`).\n",
        "- `num_layers` = 12. This is the number of transformer blocks in the model (both encoder and decoder).\n",
        "- `num_heads` = 12. This is the number of attention heads in the multi-head attention mechanism. Each head will produce a different representation of the input text, and the results will be concatenated together. Remember that the output of each attention head is concatenated. We have 12 heads, each producing a 64-dimensional output, so the final output will be 12 * 64 = 768-dimensional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwDEsaC8TN9o"
      },
      "source": [
        "We can now inspect the model to better understand its architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQNQIwflTN9o",
        "outputId": "c9b339e9-bb66-4b24-d843-bdb990b88dbb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 768)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDsbxSGuTN9o"
      },
      "source": [
        "We see that the model has a `shared` Embedding layer, an `encoder` and a `decoder`, and a final `lm_head`.\n",
        "\n",
        "We can look into the token embedding first.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "varyGekJTN9o"
      },
      "source": [
        "### Tokens embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JoBKI9UTN9o",
        "outputId": "33977620-fe01-4850-e21e-361a9b471dfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(32128, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "model.shared"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15eSN0OiTN9o"
      },
      "source": [
        "First, we can verify that this `shared` embedding layer, as the name suggests, is shared between the encoder and the decoder.\n",
        "\n",
        "We do so by checking the id of the embedding layer with the embedding layers found in the encoder and decoder (`model.encoder.embed_tokens` and `model.decoder.embed_tokens`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXLZbB_kTN9o",
        "outputId": "b57cbdad-5e0b-419d-d3d9-e49ab51ba264"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "id(model.shared) == id(model.encoder.embed_tokens) and id(model.shared) == id(model.decoder.embed_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G55Rln8QTN9o"
      },
      "source": [
        "Next, we note that the embedding layer has 32128 tokens.\n",
        "\n",
        "This is not exactly the number of tokens we saw before (32100). The extra 28 tokens are \"leftovers\". 32128 = 251 * 128 is a more \"GPU friendly\" number, and it's used to speed up the computation (same reason why we often see batch sizes that are powers of 2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cPTmffCTN9o"
      },
      "outputs": [],
      "source": [
        "words = [\n",
        "    \"chair\",\n",
        "    \"table\",\n",
        "    \"plate\",\n",
        "    \"knife\",\n",
        "    \"spoon\",\n",
        "    \"horse\",\n",
        "    \"goat\",\n",
        "    \"sheep\",\n",
        "    \"cat\",\n",
        "    \"dog\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doEwNljGTN9o",
        "outputId": "66fd3908-5d06-4e90-c447-650dee51cf00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 3533,   953,  3829, 10821, 14987,  4952, 18174, 15184,  1712,  1782])\n",
            "(10, 768)\n"
          ]
        }
      ],
      "source": [
        "word_tokens = tokenizer(words, return_tensors=\"pt\", padding=True)[\"input_ids\"][:, 0]\n",
        "print(word_tokens)\n",
        "token_embeddings = model.shared(word_tokens).cpu().detach().numpy()\n",
        "print(token_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "mru_MnpHTN9o",
        "outputId": "20309afa-e491-40cf-aeb2-9159a5fc7761"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(token_embeddings)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "ax.scatter(X_pca[:, 0], X_pca[:, 1])\n",
        "for i, word in enumerate(words):\n",
        "    ax.text(X_pca[i, 0]+5, X_pca[i, 1]+5, word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "DfaTlWKTTN9p",
        "outputId": "63d488e8-d93f-40d7-feae-da86b9df9947"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "cosine_similarity(token_embeddings)\n",
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "cax = ax.imshow(cosine_similarity(token_embeddings), cmap=\"coolwarm\")\n",
        "fig.colorbar(cax)\n",
        "plt.xticks(range(len(words)), words, rotation=90)\n",
        "plt.yticks(range(len(words)), words);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Urx2Dt-WTN9p"
      },
      "source": [
        "### Encoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHe8r9tKTN9p"
      },
      "source": [
        "The model's encoder contains various transformer layers (each one attention, feed-forward, and normalization layers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFaGGJwZTN9p",
        "outputId": "d131ac23-0fdd-44d4-c514-4fda9e65c386"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5Stack(\n",
              "  (embed_tokens): Embedding(32128, 768)\n",
              "  (block): ModuleList(\n",
              "    (0): T5Block(\n",
              "      (layer): ModuleList(\n",
              "        (0): T5LayerSelfAttention(\n",
              "          (SelfAttention): T5Attention(\n",
              "            (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (relative_attention_bias): Embedding(32, 12)\n",
              "          )\n",
              "          (layer_norm): T5LayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (1): T5LayerFF(\n",
              "          (DenseReluDense): T5DenseActDense(\n",
              "            (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "            (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (act): ReLU()\n",
              "          )\n",
              "          (layer_norm): T5LayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1-11): 11 x T5Block(\n",
              "      (layer): ModuleList(\n",
              "        (0): T5LayerSelfAttention(\n",
              "          (SelfAttention): T5Attention(\n",
              "            (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "          )\n",
              "          (layer_norm): T5LayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (1): T5LayerFF(\n",
              "          (DenseReluDense): T5DenseActDense(\n",
              "            (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "            (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (act): ReLU()\n",
              "          )\n",
              "          (layer_norm): T5LayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (final_layer_norm): T5LayerNorm()\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "model.encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emtZviHqTN9p"
      },
      "source": [
        "The `block` attribute is a list of `T5Block` modules, and contains the actual transformer layers. Indeed, we can check (as previously stated) that we have 12 encoder layers in the encoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9NJSJNITN9p",
        "outputId": "6b4d5ef9-794b-455e-ea3f-702e30e26266"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "len(model.encoder.block)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jps1qDJfTN9p"
      },
      "source": [
        "Each of the modules inside of the `block` is composed of a `T5LayerSelfAttention` module (attention layer), followed by a `T5LayerFF` module (feed-forward layer).\n",
        "\n",
        "Remember that there are some other details (e.g., normalization layers, or dropouts) that are shown below, but we will not discuss them in detail here.\n",
        "\n",
        "As a reminder, this is the architecture of a single encoder block.\n",
        "\n",
        "![encoder.png](https://github.com/GameRule17/llm-labs-polito-notebooks/blob/main/lab02/images/encoder.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEWkgKWRTN9p",
        "outputId": "b046f07b-9d07-439d-c829-0bb023629f45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5Block(\n",
              "  (layer): ModuleList(\n",
              "    (0): T5LayerSelfAttention(\n",
              "      (SelfAttention): T5Attention(\n",
              "        (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (relative_attention_bias): Embedding(32, 12)\n",
              "      )\n",
              "      (layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): T5LayerFF(\n",
              "      (DenseReluDense): T5DenseActDense(\n",
              "        (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "        (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (act): ReLU()\n",
              "      )\n",
              "      (layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "model.encoder.block[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa2IHjb2TN9p"
      },
      "source": [
        "Notice that the $W_q$, $W_k$, and $W_v$ matrices are 768x768. But, we stated that each attention is 64-dimensional, so they should be 768x64!\n",
        "\n",
        "However, remember that we have 12 heads: instead of producing 12 different heads, we instead efficiently represent all matrices inside of a single matrix. In addition, there is no need for concatenating the results: the output will already be the concatenation of all heads.\n",
        "\n",
        "The $W_o$ matrix is 768x768, i.e. `d_kv`*`num_heads` x `d_model`, as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXX6yixVTN9p"
      },
      "source": [
        "### Decoder\n",
        "\n",
        "We can inspect the decoder in the same way. Remember the decoder's architecture!\n",
        "\n",
        "![decoder.png](https://github.com/GameRule17/llm-labs-polito-notebooks/blob/main/lab02/images/decoder.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GphZqIiUTN9p",
        "outputId": "6d6ecb86-d605-4d46-fd8c-ba1e9ae8d196"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5Block(\n",
              "  (layer): ModuleList(\n",
              "    (0): T5LayerSelfAttention(\n",
              "      (SelfAttention): T5Attention(\n",
              "        (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (relative_attention_bias): Embedding(32, 12)\n",
              "      )\n",
              "      (layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): T5LayerCrossAttention(\n",
              "      (EncDecAttention): T5Attention(\n",
              "        (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "      )\n",
              "      (layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): T5LayerFF(\n",
              "      (DenseReluDense): T5DenseActDense(\n",
              "        (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "        (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (act): ReLU()\n",
              "      )\n",
              "      (layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "model.decoder.block[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA2jbUBPTN9q"
      },
      "source": [
        "Indeed, we find the expected architecture.\n",
        "\n",
        "An initial self-attention module, followed by a multi-head attention one (`T5LayerCrossAttention`), and finally a feed-forward module.\n",
        "\n",
        "Note that, although there is a dedicated class for cross-attention, the module still makes use of the same `T5Attention` class we also used for self-attention. This is because nothing changes in the attention mechanism itself: only the inputs are different."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCEA6CUjTN9q"
      },
      "source": [
        "Finally, note that the model's `lm_head` is a linear layer that takes the output of the decoder (768-dimensional) and maps it to the vocabulary size (32128)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu_IGDmSTN9q",
        "outputId": "ca70c465-c907-44e6-a357-6d987c483122"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=768, out_features=32128, bias=False)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model.lm_head\n",
        "# in the next token that we should generate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHH_sByjTN9q"
      },
      "source": [
        "## Token generation\n",
        "\n",
        "Let's now focus on the token generation process.\n",
        "\n",
        "Remember, we are working with an encoder-decoder architecture. The encoder processes the input text, and the decoder generates the output text.\n",
        "\n",
        "The input for the encoder is the tokenized input text. We also need to specify an input for the decoder. The decoder's input will be the currently generated sequence thus far. For the first iteration, there is nothing already generated, so we need to specify a special token to indicate the beginning of the sequence (BOS). For T5, the token will be `<pad_token>`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9XIysH0TN9q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "input_sentence = \"translate english to german: hello, how are you?\"\n",
        "\n",
        "#TODO: use the tokenizer to tokenize the input sentence as a tensor\n",
        "tokens = tokenizer(input_sentence, return_tensors=\"pt\")\n",
        "\n",
        "# input of our decoder, at the beginning something empty\n",
        "decoder_input_ids = torch.tensor([[ tokenizer.pad_token_id ]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGz6M3aYTN9q",
        "outputId": "8de5731a-cb75-49e8-a30e-2c50dfbd72a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder's input\n",
            "tensor([[13959, 22269,    12, 13692,    10, 21820,     6,   149,    33,    25,\n",
            "            58,     1]])\n",
            "\n",
            "Decoder's input\n",
            "tensor([[0]])\n"
          ]
        }
      ],
      "source": [
        "print(\"Encoder's input\")\n",
        "print(tokens[\"input_ids\"])\n",
        "\n",
        "print()\n",
        "print(\"Decoder's input\")\n",
        "print(decoder_input_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9E7_8KVTN9q"
      },
      "source": [
        "To generate the first output token (after `<pad_token>`), we call the model's __call__ method (or `forward` method) with the input text and the decoder's input."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDwEBMQefL8U",
        "outputId": "cb066c14-730d-4a9a-c73c-f9e064841a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[13959, 22269,    12, 13692,    10, 21820,     6,   149,    33,    25,\n",
              "            58,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V71Vg7WbTN9q",
        "outputId": "36009095-b824-4f14-e3de-bd4d6d087af9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['logits', 'past_key_values', 'encoder_last_hidden_state'])\n"
          ]
        }
      ],
      "source": [
        "# **tokens passes the dictionary as keyword arguments (input_ids=..., attention_mask=...)\n",
        "output = model(**tokens, decoder_input_ids=decoder_input_ids)\n",
        "print(output.keys())\n",
        "# 3 different things"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UktX_w6TN9q"
      },
      "source": [
        "We get three outputs:\n",
        "\n",
        "- `logits`: The logits for each token in the vocabulary. The logits are the output of the linear layer (the `lm_head`) that maps the decoder's output to the vocabulary size. The logits are used to compute the probabilities of each token.\n",
        "\n",
        "- `past_key_values`: The past key-values of the decoder. This is used to speed up the generation process for future tokens. Remember: the decoder is autoregressive, so we generate one token at a time. Since each token can only pay attention to past tokens, it means that the predictions made for earlier tokens will not change. Thus, we can cache them and not re-compute them. So, if we pas `past_key_values` to the model the next time we call it, it will be faster.\n",
        "\n",
        "- `encoder_last_hidden_state`: The hidden states of the last layer of the encoder. This is not used for generating the next token, but we may find it useful for other tasks (e.g., summarization)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output['logits']"
      ],
      "metadata": {
        "id": "Hc7SjFIOfa6-",
        "outputId": "1c22e50d-af25-41ef-f3d3-1bbcaa35b424",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-20.4737,  -9.7094, -15.2374,  ..., -40.6805, -40.5435, -40.5263]]],\n",
              "       grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axp4ybv-TN9q",
        "outputId": "e6d60200-13c9-4091-946f-96086ae80684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 32128])\n"
          ]
        }
      ],
      "source": [
        "print(output.logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.past_key_values[0]"
      ],
      "metadata": {
        "id": "yN4RlQnGfzmZ",
        "outputId": "85cee887-e0b3-4dda-a8be-0713d0a2eab1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[[ 8.0751e-01,  5.9590e-01, -4.6880e-01,  4.9266e-01,  1.1197e+00,\n",
              "            -1.2452e+00, -9.0581e-01, -5.2789e-01,  3.6213e-01,  3.6954e-01,\n",
              "            -4.3455e-02, -8.5433e-01, -6.6289e-01, -4.9530e-02,  5.1809e-01,\n",
              "            -8.5448e-01, -4.5317e-01,  5.9210e-01, -2.5630e-01,  9.7839e-04,\n",
              "            -5.9754e-01, -1.8106e+00, -1.5930e+00,  5.2041e-01, -3.8632e-01,\n",
              "             4.0855e-01,  1.7834e+00,  4.0360e-01, -1.1653e+00, -5.5640e-01,\n",
              "            -5.5420e-01,  4.8449e-01, -5.6703e-01,  4.0686e-01, -1.3294e+00,\n",
              "            -4.6914e-01,  4.6921e-01, -3.6158e-01,  5.2256e-01, -3.2758e-01,\n",
              "             3.6369e-01, -1.1385e-01,  4.4046e-01, -1.8292e-01, -4.6193e-01,\n",
              "             2.3514e-02,  1.1758e-01, -5.2525e-01, -5.6002e-01, -7.8300e-01,\n",
              "             2.6148e-01, -2.4737e+00,  4.7007e-01, -2.6592e-01, -1.5485e+00,\n",
              "             3.2745e+00,  9.0812e-01,  7.0409e-01, -2.0156e-02, -8.3044e-02,\n",
              "             6.8403e-01, -7.7884e-01,  5.1766e-01, -3.4012e-01]],\n",
              " \n",
              "          [[-6.6438e-01,  2.5151e+00,  6.8428e-01,  4.4015e-01, -8.3518e-01,\n",
              "            -9.9665e-01,  2.8279e+00, -7.2212e-01, -1.0688e+00, -9.4019e-01,\n",
              "             2.7050e+00, -6.0149e-01, -1.4592e+00, -1.2582e+00, -4.9177e-01,\n",
              "             1.3218e+00, -8.9681e-01,  9.4169e-01, -1.2019e+00, -2.4484e+00,\n",
              "             6.8547e-01, -2.0507e+00,  1.0435e+00,  2.7931e-01,  3.2697e+00,\n",
              "            -3.2134e+00,  3.8625e+00,  1.2923e-01,  1.1023e+00,  6.3996e-01,\n",
              "            -3.6581e-01, -1.7155e-02,  1.1789e+00,  2.0449e+00,  3.4693e+00,\n",
              "            -2.3352e+00,  1.2630e-02,  1.0273e+00, -1.2626e+00, -2.2317e+00,\n",
              "             2.4374e+00,  7.9716e-01,  1.2864e+00, -2.5043e+00, -2.7001e+00,\n",
              "            -8.3859e-01,  7.8593e-01, -1.8879e-01, -3.4402e-01, -5.0461e-01,\n",
              "            -5.2435e-01,  1.2397e+00, -4.4922e-01,  9.8829e-01, -2.1489e+00,\n",
              "            -2.5911e+00,  1.3928e+00,  3.8486e-03,  2.0592e+00, -8.3416e-01,\n",
              "            -3.8336e-01, -1.4383e+00, -1.4259e+00,  1.1669e+00]],\n",
              " \n",
              "          [[ 3.9742e-01, -3.5315e+00,  1.1719e+00, -1.6182e+00,  8.7969e-01,\n",
              "             2.1931e+00, -2.1199e+00,  4.7292e-01,  3.0253e+00, -1.5700e+00,\n",
              "             2.1954e-01,  2.5871e+00,  2.2306e+00, -7.9655e-01, -3.9953e-01,\n",
              "            -2.9191e+00, -2.5449e+00, -3.6712e+00, -3.9486e+00,  1.6595e+00,\n",
              "            -2.1392e-01, -2.1536e-01, -2.2524e+00,  9.9000e-01, -8.9700e-01,\n",
              "            -1.2655e+00, -5.0634e-01,  4.6596e-01,  1.0823e+00, -7.5566e-01,\n",
              "             1.4327e+00, -4.7581e-01,  2.2824e+00,  6.7650e-01,  8.2387e-01,\n",
              "             3.9348e+00, -1.7866e+00,  3.5054e+00,  2.9925e+00, -9.7865e-01,\n",
              "            -3.1659e+00,  5.9384e-01, -3.4197e+00,  1.9262e+00, -2.1253e-01,\n",
              "            -2.2707e+00,  3.4668e-01, -1.3427e+00,  1.8556e+00, -2.1940e+00,\n",
              "             3.2545e+00, -1.2743e+00,  1.6327e+00, -1.3848e+00,  2.2545e-01,\n",
              "             2.5674e+00,  3.1222e+00,  5.4801e-01, -3.8870e+00,  2.1618e+00,\n",
              "             2.3690e+00, -1.1180e+00, -2.0904e+00, -2.4539e+00]],\n",
              " \n",
              "          [[ 5.0950e-01, -1.1539e-01, -4.1786e-01,  1.4453e-02, -1.2190e-01,\n",
              "            -3.5427e-01,  4.8045e-01, -2.0790e-01,  1.0690e-01,  7.2281e-01,\n",
              "             5.6891e-01,  5.6125e-02, -2.2433e-01, -1.7975e-01, -1.0087e-01,\n",
              "             3.4681e-01,  3.3604e-01,  5.7168e+00, -1.1532e-01, -3.5277e-01,\n",
              "             2.9852e-02, -1.4957e+00, -2.0898e-01, -1.3193e-01, -1.0764e+00,\n",
              "            -4.8846e-01, -7.1031e-01,  4.6251e-01,  2.7927e-01, -2.2378e-02,\n",
              "             1.8062e+00, -6.1509e-02, -8.8988e-02,  7.7264e-01,  2.1664e-01,\n",
              "            -4.4970e-01,  3.6892e-01,  6.0727e-01,  4.3108e-02,  3.1033e-01,\n",
              "            -1.1146e-01, -8.9333e-01,  3.4001e-01,  2.1367e-01,  1.2327e-01,\n",
              "            -7.6496e-02,  3.6363e-02, -4.8496e-01, -4.7512e-02, -1.6345e-01,\n",
              "            -3.4160e-01, -4.5084e-01, -2.4742e-01,  1.5852e+00, -5.2016e-01,\n",
              "             1.5665e-01, -1.6863e-01,  1.1154e-01,  4.4352e-01,  3.6107e-01,\n",
              "             5.1278e-02,  9.9771e-01,  2.1851e-01,  3.9310e-01]],\n",
              " \n",
              "          [[ 9.0783e-02, -5.2427e-01, -2.0909e+00, -1.5422e+00,  1.7570e-02,\n",
              "             1.1699e+00, -4.2711e-01, -9.8981e-02,  9.5342e-01,  3.3095e-01,\n",
              "            -4.7372e-01,  5.5016e-01,  1.6081e+00, -7.4873e-01, -4.9377e-01,\n",
              "            -1.2235e+00, -2.1559e+00,  1.6294e+00,  2.4981e+00, -1.5355e+00,\n",
              "            -8.9766e-01, -3.6694e+00, -1.1564e-01, -1.1093e+00,  3.8158e-01,\n",
              "            -1.6573e+00,  8.4503e-01,  8.3904e-01, -8.3633e-02,  1.5096e+00,\n",
              "            -9.2405e-01, -2.6137e-01, -5.2875e-01,  8.0454e-01,  2.6376e-01,\n",
              "             7.3573e-01, -4.6772e-01, -2.1155e-01, -4.6287e-01,  2.1210e-01,\n",
              "             9.4155e-01, -1.5052e+00, -2.0146e-01, -1.3228e-01,  5.7016e-01,\n",
              "            -4.6246e-01, -5.0075e-01, -7.6358e-02,  2.3014e-01, -1.2918e+00,\n",
              "             6.0679e-01,  7.8107e-02,  2.2665e+00,  2.1073e-01,  5.3913e-01,\n",
              "             6.9107e-01,  9.9660e-01, -1.5393e+00, -1.0782e+00,  4.1038e-01,\n",
              "             2.4894e+00, -2.1641e+00, -1.9685e+00, -1.8779e+00]],\n",
              " \n",
              "          [[ 2.8266e-01, -4.0253e-01,  2.1461e-01, -8.5459e-02, -8.8574e-02,\n",
              "             2.0529e-01, -4.9773e+00, -2.6139e-02, -2.5218e-01,  3.5628e-01,\n",
              "            -6.3628e-01,  3.6137e-01, -1.6117e-01, -2.0351e-01,  5.8478e-01,\n",
              "            -2.8578e-01, -2.5785e-01,  2.8788e-01,  1.2133e-01, -1.2644e+00,\n",
              "             1.2791e+00, -1.9451e-01,  4.4943e-01,  1.0352e-01,  3.2953e-01,\n",
              "            -6.6074e-01,  4.9375e-01, -1.6468e-02,  1.1274e-01,  4.0464e-01,\n",
              "            -1.8936e-02, -7.3703e-02, -2.3792e-01, -1.2765e-01,  1.6298e+00,\n",
              "             2.1280e-02, -2.8000e-01, -1.4488e-01, -1.7418e-01,  2.3482e-01,\n",
              "             1.9675e-01,  9.6946e-02, -2.2366e-01,  4.5381e-01, -2.7155e-01,\n",
              "             3.2703e-02, -2.7884e-01,  9.1267e-02,  2.4779e-02,  1.5141e-01,\n",
              "             1.4472e-01,  3.6377e-03, -9.2628e-02, -4.0295e+00, -1.4378e-01,\n",
              "             3.8275e-01, -3.2757e-02, -2.4571e-01, -2.8731e-01,  2.9902e-01,\n",
              "            -2.9039e-01,  1.1138e-01,  4.0494e-02, -3.3153e-01]],\n",
              " \n",
              "          [[ 7.6214e-01, -7.4628e-01, -9.6668e-01,  1.1067e+00,  1.1446e+00,\n",
              "            -9.4385e-01, -1.8795e+00, -9.3064e-01,  1.7300e+00, -1.4664e+00,\n",
              "            -2.3141e-01, -3.5233e+00, -4.5847e+00,  7.1642e-01,  7.4307e-01,\n",
              "            -5.2633e-01, -1.5345e+00,  2.0310e+00,  6.6826e+00,  1.1144e+00,\n",
              "            -1.8575e+00, -1.0726e+00,  6.4875e-01, -1.2714e+00, -7.5589e-01,\n",
              "            -1.0819e-02, -1.4056e+00, -7.1250e-02, -2.6511e+00, -2.2563e+00,\n",
              "            -2.1769e-01, -2.3009e+00, -9.8707e-01,  3.9883e-02, -2.3158e+00,\n",
              "             1.8638e-01,  5.1719e-01, -1.4830e+00, -4.6418e+00, -1.4803e+00,\n",
              "             5.2249e-02,  1.1654e+00, -2.2894e+00, -2.5954e-01,  1.5796e-01,\n",
              "             2.1164e+00, -1.5284e+00, -9.3902e-01,  1.0677e+00, -1.9075e+00,\n",
              "             1.7636e-01, -1.8908e-01,  1.2209e+00,  1.6150e+00,  3.7917e-01,\n",
              "            -6.4760e-01, -2.2319e+00,  7.3769e-01,  4.3802e+00, -1.2444e+00,\n",
              "            -2.1253e+00, -2.7476e+00,  6.3747e-01,  2.2082e+00]],\n",
              " \n",
              "          [[ 1.3045e+00,  6.8440e-01,  2.0830e-01, -5.6154e-02, -2.5631e-01,\n",
              "             4.5208e-02,  1.5704e+00,  1.6998e-01,  2.3718e-01, -7.4239e-01,\n",
              "             6.7178e-01, -1.0560e-02,  1.1381e+00,  1.2160e-01,  7.5119e-01,\n",
              "             2.1111e-01, -3.5777e-01,  7.2123e-01,  2.3249e-02,  3.1410e-02,\n",
              "            -4.3115e-01,  1.4348e-01,  2.0406e-01,  6.2697e-01, -8.2221e-01,\n",
              "             1.0803e+00,  3.1962e-01, -4.7729e-01, -2.4237e-01, -5.6162e-02,\n",
              "            -4.2656e+00, -3.1590e-01,  7.0341e-01, -5.4635e-01, -5.2035e-01,\n",
              "             2.0628e-01, -4.8932e-01,  1.6150e-01, -3.0999e-02,  6.5778e-01,\n",
              "            -3.0612e-01, -7.6944e-02, -1.1452e-01, -1.2565e-01, -3.5534e-01,\n",
              "            -1.8702e-02, -2.4255e-01, -2.2292e-01,  7.9682e-01,  1.7907e-01,\n",
              "            -2.7601e-01, -9.6524e-02, -7.6748e-01,  2.4381e-01,  1.6510e-01,\n",
              "             9.1589e-01,  3.1190e-01, -6.5590e-02, -6.8282e-01, -1.3295e-01,\n",
              "             4.1992e-01,  2.2115e-01,  2.9790e-01, -3.2787e-01]],\n",
              " \n",
              "          [[-3.2410e+00,  5.0518e-01,  3.6045e-01, -7.8662e-02, -5.4112e-01,\n",
              "             3.7795e-01,  4.6643e-01, -2.5400e-01,  2.0056e-01,  2.3854e-01,\n",
              "             3.3020e-01, -1.3828e+00,  5.4292e-01,  1.0491e+00,  9.9038e-01,\n",
              "             7.3971e-01,  1.0515e+00,  4.7411e-01, -9.2982e-02,  5.4541e-02,\n",
              "             8.8933e-01,  6.7825e+00,  7.3178e+00, -1.4407e+00,  2.3846e+00,\n",
              "             2.3838e-01, -3.3341e-01,  1.0003e+00,  6.5478e-02, -1.1081e+00,\n",
              "             2.1046e+00,  2.3697e-01,  2.8534e+00,  9.2585e-01, -4.8854e-01,\n",
              "             9.5412e-01,  6.2626e-01, -9.5322e-01, -3.2681e-01, -2.6051e-01,\n",
              "             1.7154e+00,  1.8847e+00,  5.1519e-01,  6.0730e-01,  3.4397e-01,\n",
              "             3.8271e-01, -4.5334e+00, -1.7938e+00,  4.4969e-01, -5.2151e-01,\n",
              "            -2.7214e-01, -2.6888e+00,  4.8625e-01,  1.0270e+00,  1.2723e+00,\n",
              "             4.1502e-01, -5.2000e-02,  7.6593e-01, -1.8545e-01, -4.4413e-01,\n",
              "            -2.6891e-01, -3.6429e-01, -1.8426e+00, -2.2105e-01]],\n",
              " \n",
              "          [[ 1.7477e+00,  8.0151e-01,  1.1603e+00, -4.3552e-01, -1.7682e+00,\n",
              "             7.7111e-01, -1.7022e+00, -5.1787e-01,  8.6628e-01,  4.6605e-02,\n",
              "            -2.9641e-01,  1.5568e+00, -5.3659e-01, -2.0689e-01,  1.7993e+00,\n",
              "             2.5183e+00,  1.2099e+00, -2.1709e+00,  7.9104e-01, -2.0796e-01,\n",
              "             8.5769e-01,  6.2331e-01, -1.8235e-01, -3.6646e-02, -5.2813e-01,\n",
              "             1.3521e+00, -2.0734e+00,  1.1725e+00,  8.7907e-02, -9.3943e-01,\n",
              "            -1.6128e+00,  2.4609e-01, -1.7574e+00,  4.5855e-01, -4.0243e-01,\n",
              "             2.1226e+00, -5.3734e-01, -5.6601e-01, -2.4444e-01, -7.6732e-01,\n",
              "            -1.3217e+00,  4.6525e-02, -2.5592e+00, -3.9319e-01,  1.2489e-02,\n",
              "            -6.4939e-01,  2.2698e-01,  1.8445e+00, -1.4952e+00,  5.6337e-01,\n",
              "             1.5649e+00, -5.3624e-01, -3.2328e-01,  4.1266e-01,  3.0715e-01,\n",
              "             3.4660e-01, -1.9704e+00, -7.0918e-01, -1.3628e+00, -1.2425e-01,\n",
              "            -4.2060e-01, -9.4223e-01, -1.2174e+00,  9.9721e-01]],\n",
              " \n",
              "          [[-2.3004e+00,  1.1520e-01, -2.6748e+00, -1.7856e-01, -7.5062e-01,\n",
              "            -2.1346e+00, -8.9667e-01, -9.5426e-01, -1.1695e+00, -1.7084e+00,\n",
              "            -6.0532e-01, -3.1650e-01,  3.4158e+00, -3.7582e-01, -9.7813e-01,\n",
              "            -1.0293e+00,  3.7865e-01, -5.9427e-01, -4.0819e-01, -3.2543e-02,\n",
              "            -2.6261e-01,  5.8526e-01, -2.0987e+00,  3.5395e-02,  5.3047e-01,\n",
              "             2.9342e-01, -2.2651e+00,  5.7264e-01, -3.5205e+00,  5.5058e-01,\n",
              "             8.1334e-01, -1.6410e+00, -3.3278e+00, -1.9863e+00, -1.1622e+00,\n",
              "            -9.8207e-01, -6.5927e-01,  6.7355e-01,  6.4456e-01,  1.4903e+00,\n",
              "             6.4345e-02, -1.4957e-01,  7.2424e-01,  1.2147e+00, -1.4314e+00,\n",
              "            -1.2498e+00, -1.7379e+00, -1.7312e+00,  1.3057e-01,  6.6908e-01,\n",
              "            -9.1935e-01,  1.8527e+00,  1.7652e+00, -6.2223e-01,  2.9162e-01,\n",
              "            -2.8171e-01,  1.1985e+00,  1.3022e+00, -1.1550e+00, -2.1856e+00,\n",
              "            -2.3852e-01, -1.1235e+00, -1.4995e+00, -3.5250e-01]],\n",
              " \n",
              "          [[-2.5186e+00,  1.1486e-01, -1.4743e+00,  2.9450e-01, -3.5930e-01,\n",
              "            -1.2206e-01,  9.9522e-01,  2.8087e+00, -5.0892e-01, -1.1018e+00,\n",
              "             1.4972e+00, -4.9256e+00, -1.1725e+00, -2.6221e+00,  3.0782e+00,\n",
              "             3.2935e-01, -7.4319e-01,  3.7398e-01, -1.4291e+00,  9.9068e-01,\n",
              "             5.5225e-01, -9.9546e-01,  7.4577e-01, -1.6923e+00,  1.5145e+00,\n",
              "             1.2164e+00,  3.6171e+00,  1.5088e+00, -2.2028e-01,  5.5169e-01,\n",
              "            -2.8239e+00,  1.2137e+00, -3.3123e+00,  2.1339e+00,  7.7547e-01,\n",
              "             1.7777e+00,  4.0198e+00, -1.9020e+00, -2.0366e+00,  1.4539e+00,\n",
              "            -1.8763e+00, -2.9492e+00,  1.3737e+00,  1.3740e+00,  1.7966e-02,\n",
              "             5.7966e-01,  2.4825e+00, -1.4572e-01, -7.6962e-01, -1.0327e+00,\n",
              "             9.0368e-01,  2.4004e+00, -4.4174e-01,  4.8741e-01,  2.6565e+00,\n",
              "            -3.9589e-02,  6.6115e-01,  1.4014e+00, -1.8060e+00,  2.7097e+00,\n",
              "             9.4462e-01,  6.7022e-02,  3.8745e+00, -9.3342e-01]]]],\n",
              "        grad_fn=<CatBackward0>),\n",
              " tensor([[[[ 8.0797e-02,  2.0074e-01,  2.4472e-01, -2.4325e-01,  1.8291e-01,\n",
              "            -4.8938e-02, -7.4334e-02,  8.1350e-01,  5.7112e-01, -1.1500e-01,\n",
              "             1.0180e+00,  3.0636e-01,  2.6027e-01, -1.0666e-01,  1.6973e-01,\n",
              "             4.1651e-01, -7.9239e-01, -1.9766e-01, -7.0111e-02, -8.3550e-02,\n",
              "            -2.6552e-01,  7.8436e-01,  5.5063e-01,  6.5712e-01,  1.0277e+00,\n",
              "             3.3380e-01, -1.2935e-01,  4.2086e-01,  5.8501e-01, -8.7604e-02,\n",
              "            -2.0922e-01, -6.4654e-01, -8.8600e-02, -3.8118e-01, -4.3837e-01,\n",
              "             9.7070e-01,  1.0664e-01,  2.9309e-01, -3.6307e-01,  2.0858e-02,\n",
              "            -3.0823e-01, -4.0209e-01, -8.5255e-02,  1.1139e-01, -7.0446e-01,\n",
              "            -4.5242e-01,  4.0139e-01, -8.4357e-01,  1.7323e-01,  3.4771e-01,\n",
              "            -2.0160e-01, -3.7030e-01,  4.9751e-01, -5.2509e-01,  5.8836e-01,\n",
              "            -5.3463e-02,  2.3889e-01, -4.4121e-01,  2.0628e-01, -1.1870e+00,\n",
              "            -1.4896e+00, -7.7283e-01, -2.0247e+00, -9.7007e-01]],\n",
              " \n",
              "          [[ 1.7627e-03, -1.9782e-02,  2.6943e-02,  7.7908e-02, -4.7563e-01,\n",
              "            -3.7441e-01, -2.1759e-01,  2.2998e-01, -1.0742e-01, -1.0645e-01,\n",
              "            -4.2435e-01,  1.9487e-01, -8.4524e-02, -1.4350e-01, -1.8272e-01,\n",
              "            -2.7574e-01,  2.5960e-01,  1.7819e-01, -2.3473e-01,  1.3425e-01,\n",
              "             6.6344e-02, -1.8181e-01,  1.9246e-01,  2.4808e-02, -1.1681e-01,\n",
              "             8.1470e-03, -2.5204e-01, -2.6440e-01,  2.3750e-02,  3.3835e-01,\n",
              "             4.0397e-05, -4.7966e-01, -3.4478e-01, -1.6870e-01, -3.3250e-01,\n",
              "             9.9180e-02,  2.5390e-01,  1.5437e-01,  1.2244e-01, -1.3855e-01,\n",
              "             5.3972e-01,  3.4389e-01, -1.1905e-02,  2.3492e-01, -2.5889e-01,\n",
              "             4.8083e-03, -4.1535e-01,  4.7595e-01,  5.3232e-02, -1.2940e-01,\n",
              "            -6.0512e-02,  1.9489e-01, -1.4638e-01, -1.3416e-01, -2.8969e-02,\n",
              "             1.3548e-01,  1.9517e-01,  5.5012e-01,  2.6876e-01,  1.7190e-01,\n",
              "            -1.3616e-01,  2.4894e-01,  5.4807e-02,  6.1283e-02]],\n",
              " \n",
              "          [[-4.4625e-02,  1.2959e-02, -1.9856e-02, -2.6960e-04,  4.0933e-02,\n",
              "             1.2990e-02,  4.1003e-02, -3.8616e-02, -1.0357e-01,  2.7255e-02,\n",
              "            -2.6935e-02,  4.9463e-02, -9.8953e-04,  3.7723e-02,  4.8330e-02,\n",
              "            -8.8295e-02, -1.4686e-01,  6.8777e-02, -9.3608e-03, -4.3165e-02,\n",
              "            -8.9443e-02, -4.7257e-04,  1.6622e-01, -2.3621e-01, -1.7492e-01,\n",
              "            -1.3718e-01, -3.2427e-02, -2.4181e-02, -5.0062e-02, -5.6694e-02,\n",
              "             1.3067e-01,  6.4568e-02,  6.5276e-02,  3.7274e-02,  4.2521e-02,\n",
              "            -1.7188e-01, -3.7153e-02,  2.1171e-02, -1.6264e-01,  6.8564e-02,\n",
              "            -5.8675e-02, -9.4102e-02, -9.0568e-02, -1.7186e-02, -1.0426e-01,\n",
              "            -3.9616e-02, -2.0311e-01,  6.6953e-02, -2.1582e-02, -7.0676e-02,\n",
              "            -2.3553e-02, -4.0411e-03,  1.5146e-02,  3.2538e-02, -9.6706e-02,\n",
              "             1.0702e-01,  9.3301e-02, -1.0346e-01,  2.4193e-01, -2.5319e-02,\n",
              "             5.2766e-03,  1.8716e-01, -3.1861e-03, -6.1551e-02]],\n",
              " \n",
              "          [[-5.4209e-01,  9.9976e-01,  2.6016e-01,  1.5369e-01,  1.4414e-01,\n",
              "             2.2966e-02,  2.9197e-03,  2.1060e-01, -1.0437e-01, -9.0935e-02,\n",
              "            -1.0807e-01,  5.9142e-02,  1.2154e-01, -2.1805e-01,  2.4514e-01,\n",
              "             2.1899e-02,  1.3183e-01, -1.2778e-01, -8.6358e-01,  3.0672e-01,\n",
              "             2.4908e-01,  6.8322e-02,  1.1722e+00, -1.7583e-01, -5.9857e-02,\n",
              "            -1.6263e-01,  2.5497e-01, -2.3260e-02,  4.1582e-02, -9.0183e-02,\n",
              "             5.0085e-01,  1.2821e-01, -2.2671e-01,  1.8814e-01, -7.4506e-01,\n",
              "            -2.6312e-02,  2.0441e-01, -5.5000e-02, -1.8323e-01,  1.5548e-01,\n",
              "             1.6746e-01, -3.0651e-01,  1.9743e-01,  4.3043e-02,  1.1696e-01,\n",
              "            -7.1976e-01, -3.5592e-01,  1.4099e-02, -1.0483e-01,  1.1904e-01,\n",
              "            -3.9028e-02,  7.2879e-02, -1.3177e-01,  1.8156e-01, -1.2094e-01,\n",
              "            -3.5317e-02, -1.2503e-01,  1.4616e-01,  6.6480e-02, -2.4411e-01,\n",
              "             1.2972e-01,  5.7931e-02, -6.5680e-02,  1.2916e-01]],\n",
              " \n",
              "          [[ 1.2943e-01, -7.6200e-01,  1.7206e-01,  1.5656e-01,  3.9801e-01,\n",
              "             1.8482e-01, -1.3526e-01,  1.4024e-01, -1.6366e-02,  2.9796e-02,\n",
              "            -2.3639e-02,  6.4088e-02,  2.7776e-01,  2.4756e-01, -1.4608e-01,\n",
              "            -9.1498e-04, -3.0772e-01, -2.2188e-01,  1.4015e-01, -1.6988e-01,\n",
              "            -3.8054e-03, -2.3888e-01,  1.7060e-01, -1.3586e-01,  3.1906e-01,\n",
              "            -2.0570e-01,  1.7172e-01, -3.2992e-02, -1.9828e-02,  4.4786e-02,\n",
              "             1.9112e-01,  1.0814e-02, -1.3935e-02,  1.3276e-02, -2.0193e-01,\n",
              "            -1.5537e-01, -2.6138e-03,  1.1773e-01, -1.5620e-01, -5.5094e-02,\n",
              "             6.3284e-02, -2.2060e-01,  1.8055e-01,  2.0453e-01, -4.5160e-01,\n",
              "            -9.5200e-02, -7.4291e-02, -3.7073e-02, -1.3966e-01, -9.7141e-02,\n",
              "            -2.4110e-01, -2.3115e-01,  6.8520e-02,  2.6149e-01,  2.1589e-01,\n",
              "             9.4176e-02,  2.7245e-02, -3.6339e-02, -1.2104e-01, -3.0385e-01,\n",
              "            -1.2404e-02,  1.7853e-01,  1.6649e-01,  1.3321e-01]],\n",
              " \n",
              "          [[ 2.2194e-01,  7.8477e-02, -1.2938e-01, -3.8282e-01,  1.8455e-02,\n",
              "            -1.4559e-01,  2.4744e-01,  2.0387e-01,  7.2230e-01, -1.2193e-01,\n",
              "            -2.8043e-02, -7.9977e-02,  1.6367e-01,  2.3255e-01, -1.1721e-01,\n",
              "             9.9724e-02,  1.8204e-02,  5.6319e-02, -1.0680e-02,  4.2620e-01,\n",
              "             1.6051e-01,  2.0388e-02, -1.1436e-01, -3.0970e-02, -1.6000e-01,\n",
              "             1.2359e-01,  2.6942e-01,  5.6608e-02,  1.8056e-01,  1.9652e-01,\n",
              "             4.4544e-02, -1.4046e-01,  1.2171e-01, -1.0363e-02,  2.0391e-01,\n",
              "            -1.9505e-01,  2.1203e-01,  8.9177e-02, -2.8597e-02,  1.0333e-01,\n",
              "             9.1204e-02,  9.0809e-02,  1.7146e-01, -9.7472e-02,  1.1316e-01,\n",
              "             1.2505e-01, -1.7954e-01, -3.5788e-01, -4.3298e-03,  5.6174e-01,\n",
              "             9.1996e-02, -7.9028e-03,  5.5515e-02, -5.4020e-02,  1.1152e-01,\n",
              "            -2.7618e-02,  6.7676e-02, -5.5494e-02,  1.3148e-01,  1.0243e-01,\n",
              "             1.9750e-01,  1.1372e-01, -1.5930e-02,  1.4663e-01]],\n",
              " \n",
              "          [[-1.0801e-01, -6.8041e-03, -2.6120e-01,  3.4594e-01, -2.2141e-01,\n",
              "             1.5312e-01,  1.5432e-01, -2.5142e-01, -2.0115e-02, -1.8119e-01,\n",
              "             3.5898e-02, -2.2593e-02,  5.3133e-02, -9.4046e-02, -4.3762e-02,\n",
              "             1.3610e-02, -9.6086e-02,  2.3839e-01,  9.7492e-02, -2.5785e-02,\n",
              "             2.5140e-01,  6.4386e-02, -2.7582e-01,  1.0092e-01, -2.6706e-01,\n",
              "             1.4031e-01, -7.1575e-02, -1.4633e-01,  1.4219e-01,  2.2800e-01,\n",
              "            -6.1522e-04,  3.4564e-02, -7.9565e-02,  2.1669e-02,  4.0309e-02,\n",
              "            -2.5172e-01,  3.4815e-02, -2.0099e-01,  1.9000e-01, -7.9208e-02,\n",
              "            -7.9196e-02, -1.5569e-01, -1.2824e-01, -7.8178e-03, -7.2494e-02,\n",
              "             1.7363e-01,  8.1864e-02,  6.6621e-02, -1.4492e-01,  1.5678e-01,\n",
              "             6.7835e-04,  1.5938e-01,  2.5417e-01,  4.7636e-02, -1.5053e-01,\n",
              "             4.6581e-02, -8.5633e-02,  3.3402e-02, -3.0154e-01, -7.9911e-02,\n",
              "            -4.0527e-02,  5.3540e-02,  1.4217e-01,  1.0859e-01]],\n",
              " \n",
              "          [[ 2.9188e-01, -1.1506e-01, -4.3853e-01,  1.3075e-01,  4.8307e-01,\n",
              "             1.1964e+00,  2.7231e-02, -6.4482e-01,  9.8903e-01,  1.3257e+00,\n",
              "            -5.0732e-02, -3.3604e-02,  2.5618e-01,  2.0894e-01,  2.7593e-01,\n",
              "            -1.4529e-01, -1.1414e-01,  4.6590e-01, -3.7445e-01,  3.7356e-02,\n",
              "             6.9562e-02,  1.2788e-01,  8.3143e-02, -1.9421e-01,  2.0081e-01,\n",
              "             3.5820e-01,  5.8533e-01, -1.5087e+00, -3.4789e-01, -2.5592e-01,\n",
              "             1.0959e-01,  1.5187e-01, -6.1999e-02,  6.2518e-01, -1.9485e-02,\n",
              "             7.2366e-02,  1.5218e-02, -4.0080e-01, -4.4024e-01,  1.8379e-01,\n",
              "            -1.6654e-01, -1.5152e-01,  5.8154e-01, -5.0357e-01, -5.4405e-01,\n",
              "            -1.4347e-01,  2.1822e-01,  6.4796e-01,  2.8207e-01,  1.5754e-01,\n",
              "            -3.4576e-02, -4.4722e-02, -1.5084e-01, -5.2411e-01,  2.5869e-01,\n",
              "             7.4176e-02, -9.6719e-01,  1.4684e-01, -5.0677e-01, -2.4988e-02,\n",
              "             7.1612e-01, -2.6534e-01,  3.1793e-01,  4.9131e-02]],\n",
              " \n",
              "          [[-1.6762e-02, -7.9350e-02, -3.6100e-04,  4.6305e-02, -9.6491e-02,\n",
              "             5.9346e-02, -7.1426e-02, -7.8099e-03, -5.4436e-02,  2.4633e-02,\n",
              "            -3.3978e-02, -1.9640e-02,  1.9175e-02, -5.6442e-02, -8.5125e-02,\n",
              "            -6.4302e-02, -2.2469e-02,  8.7482e-02,  8.6593e-02,  8.4085e-02,\n",
              "             1.0859e-02,  4.5617e-02, -1.2698e-01, -1.7134e-02,  1.1434e-01,\n",
              "             8.4611e-02,  4.4113e-02, -4.7900e-02, -6.0785e-02,  7.8928e-02,\n",
              "             1.1938e-01, -9.4878e-03,  5.8613e-02,  5.3111e-02,  1.0973e-01,\n",
              "            -1.1226e-01,  3.9057e-02,  5.8362e-02,  2.1100e-01,  1.6548e-02,\n",
              "            -8.4022e-02,  5.5279e-03, -5.1316e-02, -1.4678e-02, -7.9064e-02,\n",
              "             3.2555e-02, -7.3480e-04,  1.6399e-02,  3.4009e-02, -7.5496e-02,\n",
              "            -2.4077e-02,  8.3410e-02,  4.1017e-02,  8.9220e-02,  9.0721e-02,\n",
              "            -8.5430e-03, -7.0503e-03, -1.0142e-01,  7.9759e-02,  9.8977e-02,\n",
              "             1.1605e-01,  1.2545e-01, -8.9708e-03,  5.2697e-02]],\n",
              " \n",
              "          [[-2.3982e-01, -1.3169e-01,  3.2156e-02,  1.7660e-01,  9.1645e-02,\n",
              "             5.8097e-01,  1.3339e-02,  2.1003e-01, -4.5831e-01,  1.2958e-01,\n",
              "            -2.6269e-01, -1.1898e-01,  9.6358e-02,  2.1011e-01,  1.1993e-01,\n",
              "             1.3110e-02, -4.6368e-02,  1.2328e-01, -2.2957e-01, -1.3870e-02,\n",
              "            -7.9470e-02,  3.1644e-01, -1.0792e-01, -5.3631e-02,  4.9484e-01,\n",
              "             1.3330e-01,  1.2382e-01, -3.4223e-03, -2.1619e-01,  2.6146e-01,\n",
              "            -1.2689e-01, -1.6147e-01, -1.4804e-01, -1.3646e-01,  1.0854e-01,\n",
              "            -9.7067e-02,  3.5785e-01,  8.9237e-02,  2.1423e-01,  2.4389e-01,\n",
              "             1.5940e-01,  3.2069e-02,  1.9676e-01, -5.6328e-02,  2.0485e-01,\n",
              "             1.3444e-02,  1.6842e-02,  2.2784e-01,  4.0129e-01,  1.2056e-01,\n",
              "             7.0940e-02,  2.4394e-01, -7.6701e-02, -1.1353e-02, -1.8868e-01,\n",
              "             1.3078e-01, -7.5254e-02,  1.0736e-01,  1.7850e-01,  7.3289e-02,\n",
              "             8.0353e-02,  1.1096e-01, -4.4823e-01, -2.8592e-02]],\n",
              " \n",
              "          [[ 4.7808e-02,  1.6043e-01,  1.9411e-01, -3.5388e-01, -1.8258e-01,\n",
              "             2.5250e-01, -1.5961e-01,  7.6818e-02, -2.8257e-02,  5.4075e-02,\n",
              "             5.8154e-02, -1.7130e-03, -1.9450e-01,  1.9972e-01, -6.6186e-02,\n",
              "             5.4210e-02,  1.2594e-01,  6.1755e-02, -2.1846e-01,  1.3807e-01,\n",
              "            -4.4412e-01, -1.9590e-01, -1.4987e-01, -2.0674e-01, -5.6138e-02,\n",
              "             8.9590e-02, -2.5925e-01,  5.1154e-01, -1.6762e-01,  1.0806e-01,\n",
              "             2.1920e-02, -2.1882e-01,  2.2043e-01,  1.2553e-03,  5.5780e-01,\n",
              "             9.5284e-02, -4.7863e-02, -2.7520e-01, -9.4578e-02, -5.1578e-02,\n",
              "             6.2054e-02, -1.6798e-01, -6.9172e-02,  2.4798e-01, -5.0535e-02,\n",
              "             3.4402e-01,  1.6275e-01, -1.0098e-01,  6.3632e-02,  1.6692e-01,\n",
              "            -2.2720e-01,  2.5772e-01,  8.6055e-02,  2.0026e-01, -1.3933e-01,\n",
              "            -1.2364e-01,  1.3289e-01, -9.8049e-02,  9.2380e-02, -4.1722e-02,\n",
              "             1.4436e-02, -1.9647e-01, -2.8476e-02,  8.5031e-02]],\n",
              " \n",
              "          [[ 1.2667e-01,  7.9922e-05, -3.0136e-01, -7.9022e-02, -7.7791e-02,\n",
              "             1.3259e-01,  6.2304e-02,  6.8550e-02,  5.9034e-03, -2.6698e-01,\n",
              "            -2.6618e-02,  4.4693e-01, -2.4522e-01,  2.6941e-01,  7.4814e-02,\n",
              "             2.3134e-01,  2.4143e-01,  4.9123e-02, -2.0139e-01, -1.0233e-01,\n",
              "            -1.9566e-01,  6.7435e-03, -2.4720e-01,  3.1130e-01,  6.7376e-02,\n",
              "             3.1983e-01, -1.3359e-01, -4.4695e-02, -3.6666e-01, -5.3597e-03,\n",
              "            -3.3652e-02,  8.3703e-02, -1.5011e-01, -9.1771e-02,  4.5850e-02,\n",
              "            -6.2353e-01,  8.0132e-02,  1.9764e-01, -2.4046e-01,  2.6481e-01,\n",
              "            -8.0565e-01, -1.5412e-01,  4.5156e-01,  2.3525e-02,  1.6931e-01,\n",
              "             6.3958e-02, -2.2726e-01, -6.9550e-01, -2.9862e-01, -1.4588e-01,\n",
              "             3.1967e-01, -3.0589e-01,  1.7580e-01,  2.5594e-01, -4.0182e-02,\n",
              "            -3.3957e-01,  2.5401e-01, -1.9983e-02,  2.6592e-01,  4.8156e-01,\n",
              "             4.6104e-01,  2.3895e-01, -3.3603e-01, -1.5230e-01]]]],\n",
              "        grad_fn=<CatBackward0>),\n",
              " tensor([[[[-0.8833, -3.4285, -2.6623,  ...,  2.5274,  1.7202,  0.3825],\n",
              "           [-0.8820, -3.3164, -2.7943,  ...,  2.7805,  2.0013,  0.4679],\n",
              "           [ 0.0560, -0.5999, -1.7023,  ..., -0.3690,  2.1554,  0.9853],\n",
              "           ...,\n",
              "           [-0.7339,  0.7384,  1.0374,  ..., -0.4609,  1.6293, -0.7096],\n",
              "           [ 0.8477,  3.5175,  2.5856,  ...,  0.6772,  1.6858,  2.9344],\n",
              "           [-0.0284, -0.4705, -1.6890,  ..., -0.3350,  2.0269,  1.0855]],\n",
              " \n",
              "          [[ 1.2067, -1.1755, -1.7359,  ..., -3.4384,  2.8740,  3.1621],\n",
              "           [ 1.2819, -1.2006, -1.8315,  ..., -3.4382,  2.8235,  3.2538],\n",
              "           [ 1.0451,  0.8339,  1.1047,  ..., -1.0590, -0.6443,  0.1340],\n",
              "           ...,\n",
              "           [-0.1506,  3.0533,  1.0543,  ..., -3.7167, -0.1186, -1.3183],\n",
              "           [ 3.6786,  1.7855, -1.8197,  ..., -2.9233,  3.0090,  2.1756],\n",
              "           [ 1.1482,  0.9745,  1.0276,  ..., -1.1499, -0.1299,  0.1975]],\n",
              " \n",
              "          [[-1.3356, -3.2764,  0.4654,  ..., -0.0838,  0.9318,  2.6222],\n",
              "           [-1.4291, -3.3263,  0.4244,  ..., -0.1107,  1.0453,  2.5619],\n",
              "           [-0.5920,  1.8882, -0.8635,  ..., -0.2092,  1.3109, -0.5959],\n",
              "           ...,\n",
              "           [-1.5569,  0.4766, -3.4092,  ...,  2.9051,  1.4852, -1.6452],\n",
              "           [-0.5781,  0.9036, -0.8686,  ...,  4.3938, -1.6213,  0.1727],\n",
              "           [-0.7968,  1.9476, -1.0103,  ..., -0.1296,  1.2826, -0.8542]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.1696, -0.5412,  1.7966,  ...,  0.1816, -0.3421,  0.2772],\n",
              "           [ 0.1152, -0.3554,  1.6868,  ..., -0.1288, -0.3592,  0.4552],\n",
              "           [-0.1441, -0.2058,  0.1195,  ...,  2.9829, -1.3462,  1.1441],\n",
              "           ...,\n",
              "           [-0.1740,  1.9438, -3.4006,  ..., -0.9166, -0.4565,  2.7548],\n",
              "           [ 0.0888,  0.7551, -0.0578,  ...,  0.5793,  0.0394,  0.3661],\n",
              "           [-0.1908, -0.1121,  0.2200,  ...,  2.7549, -1.3313,  1.4044]],\n",
              " \n",
              "          [[ 2.2790, -2.1983,  3.3456,  ...,  2.1606,  0.2568,  2.1034],\n",
              "           [ 2.3940, -2.0056,  3.2450,  ...,  2.0575,  0.0957,  2.3639],\n",
              "           [-2.0265, -0.5143, -0.5704,  ...,  1.2961, -0.5049,  0.5696],\n",
              "           ...,\n",
              "           [-0.0866, -1.8152,  1.1813,  ..., -0.6559,  3.8467,  2.7601],\n",
              "           [-2.0442,  0.3130, -0.6248,  ..., -0.8157,  1.1541,  2.3263],\n",
              "           [-2.0124, -0.6749, -0.4197,  ...,  1.2078, -0.5234,  0.6094]],\n",
              " \n",
              "          [[ 0.0355,  1.5408,  1.4125,  ...,  0.1390,  0.5162,  1.1741],\n",
              "           [ 0.1263,  1.3292,  1.2091,  ...,  0.1735,  0.5965,  1.2579],\n",
              "           [ 1.0181, -1.0758, -2.3781,  ..., -1.3200, -1.1017, -0.1400],\n",
              "           ...,\n",
              "           [ 1.6813,  0.2705, -1.0450,  ...,  1.6297,  1.3547, -1.2880],\n",
              "           [ 4.4294, -1.4233, -3.3829,  ...,  1.1412,  1.6729, -0.8468],\n",
              "           [ 1.3255, -1.1553, -2.6243,  ..., -1.2533, -0.9824, -0.2783]]]],\n",
              "        grad_fn=<CatBackward0>),\n",
              " tensor([[[[ 2.1199e+00,  7.1074e-01, -5.7262e-01,  ...,  2.7415e-01,\n",
              "             1.5512e+00, -9.0206e-01],\n",
              "           [ 2.1946e+00,  7.8159e-01, -5.2954e-01,  ...,  4.4648e-01,\n",
              "             1.6276e+00, -1.0188e+00],\n",
              "           [-3.3860e-01, -5.0269e-01,  3.4490e-02,  ..., -1.4326e-01,\n",
              "            -5.1407e-01,  7.0888e-01],\n",
              "           ...,\n",
              "           [ 1.8744e+00,  1.2563e+00, -1.4942e+00,  ..., -1.3610e+00,\n",
              "            -2.1300e-01, -1.3640e+00],\n",
              "           [-2.7385e+00, -4.8814e-01, -1.2955e+00,  ...,  2.9135e-01,\n",
              "             3.3240e+00, -3.2585e-01],\n",
              "           [-5.3958e-01, -4.3387e-01, -1.4851e-02,  ..., -1.3113e-01,\n",
              "            -2.7604e-01,  5.1229e-01]],\n",
              " \n",
              "          [[ 7.6884e-01,  9.3737e-01,  1.3761e+00,  ..., -3.5549e-01,\n",
              "            -2.2543e+00, -9.8809e-01],\n",
              "           [ 8.2928e-01,  7.3308e-01,  1.4128e+00,  ..., -2.5766e-01,\n",
              "            -2.2315e+00, -9.7039e-01],\n",
              "           [-5.4192e-02, -1.5818e+00,  1.0449e-01,  ..., -1.1137e+00,\n",
              "             1.7126e-01,  3.9157e-01],\n",
              "           ...,\n",
              "           [ 1.8626e+00,  7.2521e-01,  2.2106e-01,  ...,  2.0449e+00,\n",
              "             9.7623e-01,  3.8910e-01],\n",
              "           [ 1.4948e+00,  2.8191e+00, -2.6480e-01,  ...,  9.5330e-01,\n",
              "            -1.3485e+00,  1.5104e+00],\n",
              "           [ 2.9976e-02, -1.2991e+00,  1.5138e-02,  ..., -1.0777e+00,\n",
              "            -9.0376e-02,  4.9368e-01]],\n",
              " \n",
              "          [[ 1.3984e-01, -6.2729e-01,  8.6467e-03,  ..., -1.7042e+00,\n",
              "             1.4291e+00,  1.9218e+00],\n",
              "           [ 6.3867e-02, -6.2375e-01,  2.2235e-01,  ..., -1.7725e+00,\n",
              "             1.4436e+00,  1.8826e+00],\n",
              "           [ 1.7338e-01,  2.8319e-01, -2.1849e-02,  ...,  2.5853e-01,\n",
              "             3.4624e-01, -2.4574e-03],\n",
              "           ...,\n",
              "           [-1.4421e+00, -2.6326e+00, -8.2715e-01,  ..., -8.8910e-01,\n",
              "            -1.0672e+00, -1.4648e+00],\n",
              "           [-3.7513e+00, -1.5993e+00, -1.1272e+00,  ..., -1.0667e+00,\n",
              "            -7.9915e-01,  1.4089e+00],\n",
              "           [ 2.5099e-02,  2.1600e-01,  2.8052e-02,  ...,  1.9175e-01,\n",
              "             2.7883e-01, -9.6705e-03]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-1.9051e+00,  7.9994e-01,  8.5855e-01,  ..., -1.1350e+00,\n",
              "            -1.1743e-01, -6.9277e-01],\n",
              "           [-2.0302e+00,  5.8409e-01,  6.0054e-01,  ..., -1.1550e+00,\n",
              "            -1.3007e-01, -6.2273e-01],\n",
              "           [ 4.2256e-01,  6.2395e-01, -1.8954e-01,  ...,  7.1390e-03,\n",
              "             1.7433e-01, -2.3006e-01],\n",
              "           ...,\n",
              "           [ 2.5571e+00,  1.2648e+00,  3.2510e+00,  ...,  2.5416e+00,\n",
              "            -8.7473e-01,  8.5932e-01],\n",
              "           [ 7.6204e-01, -1.9827e+00,  3.1289e-01,  ...,  2.1675e+00,\n",
              "            -1.2232e+00,  5.3278e-01],\n",
              "           [ 3.8165e-01,  6.0063e-01, -2.3451e-01,  ...,  6.3892e-02,\n",
              "             7.0873e-02, -2.4476e-01]],\n",
              " \n",
              "          [[-9.5679e-01,  7.0689e-01, -6.0956e-01,  ..., -5.3139e-01,\n",
              "             2.1485e+00, -1.2376e+00],\n",
              "           [-9.8320e-01,  5.8990e-01, -4.9026e-01,  ..., -5.0267e-01,\n",
              "             2.2650e+00, -1.4207e+00],\n",
              "           [ 1.2842e-01, -3.7059e-01,  3.3575e-02,  ...,  2.7189e-01,\n",
              "            -7.4538e-01,  2.9209e-01],\n",
              "           ...,\n",
              "           [ 2.3686e-01,  2.4515e-01, -1.5723e+00,  ..., -1.5072e+00,\n",
              "             4.9502e+00, -2.7947e-01],\n",
              "           [-1.3569e-01, -7.6175e-01, -8.4120e-01,  ..., -2.6934e+00,\n",
              "             4.4840e+00, -9.4139e-02],\n",
              "           [ 7.0420e-02, -2.3866e-01,  2.7070e-02,  ...,  7.5616e-03,\n",
              "            -8.1057e-01,  2.6353e-01]],\n",
              " \n",
              "          [[ 8.1678e-01,  1.9366e+00, -2.3153e-01,  ...,  2.1417e-01,\n",
              "             4.4062e-01,  1.6106e-01],\n",
              "           [ 1.0008e+00,  2.1571e+00, -1.9205e-01,  ...,  2.9570e-01,\n",
              "             5.5242e-01,  1.9933e-01],\n",
              "           [-3.1208e-01, -6.3597e-01,  7.3503e-03,  ...,  5.7064e-01,\n",
              "            -8.5198e-02, -6.0226e-02],\n",
              "           ...,\n",
              "           [-3.6816e-01,  2.7297e-01, -5.7915e-01,  ...,  5.1905e-01,\n",
              "            -7.3225e-01, -1.0970e+00],\n",
              "           [-7.1152e-01, -1.9223e-01, -1.9056e+00,  ..., -1.2619e+00,\n",
              "            -9.9958e-01,  2.0628e-01],\n",
              "           [-3.4397e-01, -5.6752e-01,  1.7811e-02,  ...,  3.2008e-01,\n",
              "             2.8299e-02,  4.1473e-02]]]], grad_fn=<CatBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oVuLyqVTN9r"
      },
      "source": [
        "The shape of the logits is 1x1x32128. The first dimension is the batch size, the second dimension is the number of tokens in the output sequence (we are still at a single generated token), and the third dimension is the number of tokens in the vocabulary.\n",
        "\n",
        "So what's the next word going to be? We can use greedy decoding to take the token with the highest probability."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.logits[0,0].argmax()"
      ],
      "metadata": {
        "id": "e-us_b1rgxTr",
        "outputId": "7283c561-b1f8-498e-a0bf-a2ee8d3f6904",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2501)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMWicQalTN9r",
        "outputId": "5d66d4e6-dbc9-41d8-b04b-ad51d0e877a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max probability token: 2501\n",
            "Corresponding token: Hall\n"
          ]
        }
      ],
      "source": [
        "max_proba_token = output.logits[0,0].argmax()\n",
        "print(\"Max probability token:\", max_proba_token.item())\n",
        "print(\"Corresponding token:\", tokenizer.decode(max_proba_token))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpBOoA5LTN9r"
      },
      "source": [
        "Looks like we're on the right track. We have a new token, which we can add to our `decoder_input_ids` tensor and continue with the next iteration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvDmAoDETN9r",
        "outputId": "5a34419c-ed38-463f-9496-295e6a8aa2d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   0, 2501]])\n"
          ]
        }
      ],
      "source": [
        "# .view() acts like .reshape(), but assumes that the tensor is contiguous in memory (& is faster)\n",
        "decoder_input_ids = torch.hstack([decoder_input_ids, max_proba_token.view(1, 1)])\n",
        "print(decoder_input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X55ZjEGqTN9r",
        "outputId": "52eef4d9-4d03-4180-f636-4763c54b11bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 32128])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "#TODO: use the model to generate the next token\n",
        "output = model(**tokens, decoder_input_ids=decoder_input_ids)\n",
        "output.logits.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZupH-1qTN9r"
      },
      "source": [
        "Now the output has shape 1x2x32128. We have generated two tokens!\n",
        "\n",
        "The first one, remember, will necessarily be the same as the one we produced before, since the masking mechanism prevents the model from seeing any following token.\n",
        "\n",
        "But just to be sure, let's decode both tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5RKmCoTTN9r",
        "outputId": "76278c04-86d6-4c9a-f740-a196d2c129b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token ids tensor([2501,   32])\n",
            "Mapped tokens ['▁Hall', 'o']\n",
            "Decoded string Hallo\n"
          ]
        }
      ],
      "source": [
        "# 0 -> first (and only) batch\n",
        "max_proba_tokens = output.logits[0].argmax(axis=1)\n",
        "print(\"Token ids\", max_proba_tokens)\n",
        "print(\"Mapped tokens\", list(map(reverse_vocab.get, max_proba_tokens.tolist())))\n",
        "print(\"Decoded string\", tokenizer.decode(max_proba_tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4seQlwaTN9r"
      },
      "source": [
        "We are onto something. We could go ahead and generate more tokens manually.\n",
        "\n",
        "However, we can implement our own generation loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryFxEhzITN9r",
        "outputId": "3fde7ca3-8141-42ef-fd38-9c9aa5db32e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<pad> Hallo, wie sind Sie nicht?</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# greedy deoding\n",
        "tokenizer.batch_decode(model.generate(**tokens, do_sample=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acbmbGGTTN9s",
        "outputId": "e4df215b-9f1e-4fa6-e0d0-dabd95372aa4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2501,   32])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "output.logits[0].argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVgdzqBVTN9s",
        "outputId": "7ea209dc-75dc-462a-b589-9d37cd7df8f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Hall\n",
            "Step 2: Hallo\n",
            "Step 3: Hallo,\n",
            "Step 4: Hallo, wie\n",
            "Step 5: Hallo, wie sind\n",
            "Step 6: Hallo, wie sind Sie\n",
            "Step 7: Hallo, wie sind Sie?\n",
            "Step 8: Hallo, wie sind Sie?</s>\n"
          ]
        }
      ],
      "source": [
        "\n",
        "decoder_input_ids = torch.tensor([[ tokenizer.pad_token_id ]])\n",
        "\n",
        "max_length = 50\n",
        "i = 0\n",
        "\n",
        "# util we do not reach max_length OR we generate an EOS\n",
        "while i < max_length and decoder_input_ids[0,-1] != tokenizer.eos_token_id:\n",
        "    output = model(**tokens, decoder_input_ids=decoder_input_ids)\n",
        "    max_proba_tokens = output.logits[0].argmax(axis=1) # most likely token\n",
        "    print(f\"Step {i+1}: {tokenizer.decode(max_proba_tokens)}\")\n",
        "    decoder_input_ids = torch.hstack([decoder_input_ids, max_proba_tokens[-1].view(1, 1)])\n",
        "    # hstack = attach the next word\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSLxACe-TN9s"
      },
      "source": [
        "Note that we are introducing a `max_length` parameter. This is just in case, to prevent the model from generating an infinite sequence.\n",
        "\n",
        "Now, turns out that the model has a `generate()` method that does exactly what we just did."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DsVcUhsTN9s",
        "outputId": "229f0dda-e1c3-4f2a-d485-c6d7e1f5107b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<pad> Hallo, wie sind Sie?</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "#TODO: use the model to generate a translation of the input sentence\n",
        "out_tokens = model.generate(**tokens, max_length=max_length)\n",
        "tokenizer.batch_decode(out_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69mO0oQ6TN9u"
      },
      "source": [
        "You may also empirically verify that `model.generate()` is faster than the manual loop. This is because there are some optimizations in the `generate()` method that make the generation process faster (e.g., caching the encoder's outputs, or the previous decoder's hidden states)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsTlSGdFTN9u"
      },
      "source": [
        "## Cross-attention\n",
        "\n",
        "We can now run the previous code, but now let's compute the cross-attention weights. This will help us understand what the model is paying attention to in the input sequence, when generating the next token.\n",
        "\n",
        "To compute the attention weights, we need to reload the model, passing the `output_attentions=True` parameter. This will make the model return the attention weights for each layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6c5hgULTN9u"
      },
      "outputs": [],
      "source": [
        "#TODO: load the model that returns also the output of the attentions (output_attentions=True)\n",
        "model = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoRoDEobTN9u"
      },
      "outputs": [],
      "source": [
        "# re-prepare encoder tokens and decoder tokens\n",
        "# input_sentence = \"translate from english to german: hello how are you?\"\n",
        "input_sentence = \"translate english to german: hello how are you?\"\n",
        "\n",
        "#TODO: use the tokenizer to tokenize the input sentence as a tensor\n",
        "tokens = tokenizer(input_sentence, return_tensors=\"pt\")\n",
        "\n",
        "#TODO: create the token for the decoder input (start with the <pad> token -> tokenizer.pad_token_id)\n",
        "decoder_input_ids = torch.tensor(...)\n",
        "\n",
        "#TODO: use the model to generate the output putting the decoder_input_ids as the first token (decoder_input_ids=decoder_input_ids)\n",
        "output = ...\n",
        "print(output.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nNjQW-1TN9u"
      },
      "outputs": [],
      "source": [
        "#TODO: pass in the tokenizer.batch_decode the output of the model to get the translation of the input sentence\n",
        "# `tokenizer.batch_decode() is the funnction that decodes the tokenized output of the model into a string`\n",
        "tokenizer.batch_decode(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWvPvxVITN9u"
      },
      "source": [
        "In addition to the previous values, we now have `decoder_attentions`, `cross_attentions`, and `encoder_attentions`.\n",
        "\n",
        "The names are self-explanatory. We will focus on the cross-attention to understand encoder-decoder interactions.\n",
        "\n",
        "Each of the decoder's layers has a corresponding cross-attention layer. So we expect to have 12 cross-attention layers. Indeed, the `cross_attention` is a tuple, with 12 elements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf1PmH2UTN9u"
      },
      "outputs": [],
      "source": [
        "type(output.cross_attentions), len(output.cross_attentions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA2VdL4FTN9v"
      },
      "source": [
        "The shape of any one of these attentions is the following: 1x12x1x13. Remember:\n",
        "\n",
        "- the first 1 is the batch size (a single sentence),\n",
        "- 12 are the attention heads, each one producing an attention mask,\n",
        "- 1 is the number of tokens passed as input to the decoder (just BOS, for now),\n",
        "- 11 is the number of tokens in the input sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xo590a6LTN9v"
      },
      "outputs": [],
      "source": [
        "output.cross_attentions[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T81bcvsTN9v"
      },
      "source": [
        "Let's look at the first layer's attentions.\n",
        "\n",
        "We can see that for early stages the attention is mostly focused on identifying the task (\"translate\", \"english\", \"german\").\n",
        "\n",
        "Interestingly, \"german\" gets attention from many of the heads, whereas \"translate\" and \"english\" are less attended to. We can expect this to be the case since T5 has been trained on various tasks, one of which was translation from english to other languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsFH8PulTN9v"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(4,4))\n",
        "ax.imshow(output.cross_attentions[0][0, :, 0].detach().numpy())\n",
        "input_tokens = tokenizer.tokenize(input_sentence) + [ \"</s>\" ]\n",
        "ax.set_xticks(range(len(input_tokens)), input_tokens, rotation=90);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmbCPRVVTN9v"
      },
      "source": [
        "We can check the rest of the attentions in the other layers as well.\n",
        "\n",
        "With the exception of the initial layer, the attention on \"translate\" and \"english\" is mostly gone. The attention is now focused on \"german\" and on the first word of the sentence (\"hello\").\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgUYUrMATN9v"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 10, figsize=(14, 3))\n",
        "\n",
        "ax[0].set_ylabel(\"Attention head\")\n",
        "\n",
        "for i in range(10):\n",
        "    ax[i].imshow(output.cross_attentions[i][0, :, 0].detach().numpy())\n",
        "    input_tokens = tokenizer.tokenize(input_sentence) + [ \"</s>\" ]\n",
        "    ax[i].set_xticks(range(len(input_tokens)), input_tokens, rotation=90);\n",
        "    ax[i].set_yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FltbDb4BTN9v"
      },
      "source": [
        "As a final exploration, let's check the average attention across layers and heads, for the last token generated throughout the entire sequence.\n",
        "\n",
        "In this way, we can observe how the attention shifts as we generate more tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRfRUmsDTN9v"
      },
      "outputs": [],
      "source": [
        "decoder_input_ids = torch.tensor([[ tokenizer.pad_token_id ]])\n",
        "\n",
        "attns = []\n",
        "\n",
        "max_length = 50\n",
        "i = 0\n",
        "\n",
        "while i < max_length and decoder_input_ids[0,-1] != tokenizer.eos_token_id:\n",
        "    output = model(**tokens, decoder_input_ids=decoder_input_ids)\n",
        "    max_proba_tokens = output.logits[0].argmax(axis=1)\n",
        "    print(f\"Step {i+1}: {tokenizer.decode(max_proba_tokens)}\")\n",
        "    decoder_input_ids = torch.hstack([decoder_input_ids, max_proba_tokens[-1].view(1, 1)])\n",
        "    attns.append(output.cross_attentions)\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7tg9Rh6TN9v"
      },
      "source": [
        "Note: taking the average across all heads and all layers may not necessarily be the best approach (for instance, some interesting aspects may be lost in this aggregation). However, it should give us a general idea of what the model is focusing on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9gti005TN9v"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "ax.imshow(torch.stack([ torch.stack(a).mean(axis=(0, 1, 2))[-1] for a in attns ]).detach().numpy())\n",
        "ax.set_xlabel(\"Input token\")\n",
        "ax.set_ylabel(\"Generated token\")\n",
        "\n",
        "input_tokens = tokenizer.tokenize(input_sentence) + [ \"</s>\" ]\n",
        "output_tokens = tokenizer.tokenize(tokenizer.decode(output.logits[0].argmax(axis=1)))\n",
        "ax.set_xticks(range(len(input_tokens)), input_tokens, rotation=90)\n",
        "ax.set_yticks(range(len(output_tokens)), output_tokens);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOKyBGDsTN9v"
      },
      "source": [
        "Indeed, when Hall|o|, is generated, the most attention is paid to the word \"hello\". Then the attention shifts to the rest of the sentence gradually. This shows how the decoder can focus on different parts of the input sequence as it generates different parts of the output sequence!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bc7f6fa919404acdb6df08cbbb57aeaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f90a2b7c6a844b08b82608b3b0d19c0",
              "IPY_MODEL_7a35bb9a54cb44e0979aa09f7b610f86",
              "IPY_MODEL_59c3309206954e7c8389ef22ea2dd4b1"
            ],
            "layout": "IPY_MODEL_f7cdc6b2ff124bb2a4b11f02da836bce"
          }
        },
        "0f90a2b7c6a844b08b82608b3b0d19c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_822b6a3fe202462dad1f8ef02696ff71",
            "placeholder": "​",
            "style": "IPY_MODEL_8bece923e434440cb3896c51a89973c7",
            "value": "config.json: "
          }
        },
        "7a35bb9a54cb44e0979aa09f7b610f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91f3e33f932e44febf8bcf9c335dc467",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_630d350b72134608985be5f3d3090f69",
            "value": 1
          }
        },
        "59c3309206954e7c8389ef22ea2dd4b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40f632aa04ea4edb942f19fc6861507e",
            "placeholder": "​",
            "style": "IPY_MODEL_1683c3c630bb4cfcbbb0c4a60be9805a",
            "value": " 1.21k/? [00:00&lt;00:00, 32.8kB/s]"
          }
        },
        "f7cdc6b2ff124bb2a4b11f02da836bce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "822b6a3fe202462dad1f8ef02696ff71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bece923e434440cb3896c51a89973c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91f3e33f932e44febf8bcf9c335dc467": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "630d350b72134608985be5f3d3090f69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40f632aa04ea4edb942f19fc6861507e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1683c3c630bb4cfcbbb0c4a60be9805a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9c2da5446c04ce7978401417be17f06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8cc9faef4e04b5082e8660198430dfa",
              "IPY_MODEL_91bc44d0b62f4d29ba409d08cfa1a063",
              "IPY_MODEL_10f39b471e7141ebaa9f0504a2db7868"
            ],
            "layout": "IPY_MODEL_acf6b63384ee403aa82600df52985ea8"
          }
        },
        "f8cc9faef4e04b5082e8660198430dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3310a78d3b224b60b1a6b23f3e8eef13",
            "placeholder": "​",
            "style": "IPY_MODEL_2eac061630094aeba3c3fa39ca1dc843",
            "value": "spiece.model: 100%"
          }
        },
        "91bc44d0b62f4d29ba409d08cfa1a063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5d7045ebd3d471d801abbf9aded78c2",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6698d68321c04d4f92eec10776fc5446",
            "value": 791656
          }
        },
        "10f39b471e7141ebaa9f0504a2db7868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22259431bbf34057952b152cf4888817",
            "placeholder": "​",
            "style": "IPY_MODEL_e7dc3a24ac0b4470a93783a736b9f15a",
            "value": " 792k/792k [00:00&lt;00:00, 13.5MB/s]"
          }
        },
        "acf6b63384ee403aa82600df52985ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3310a78d3b224b60b1a6b23f3e8eef13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eac061630094aeba3c3fa39ca1dc843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5d7045ebd3d471d801abbf9aded78c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6698d68321c04d4f92eec10776fc5446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22259431bbf34057952b152cf4888817": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7dc3a24ac0b4470a93783a736b9f15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8470f8c87ec446c2a1ec2d9479715396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76d651c4a3a54a91a2d78e3798e5b2ee",
              "IPY_MODEL_2adad6653a954973a7ca80cf80943c31",
              "IPY_MODEL_1a9ccea166cb4aa0bf51a9426c3cac28"
            ],
            "layout": "IPY_MODEL_291c5b112577479c8c0aa12c7fcf065d"
          }
        },
        "76d651c4a3a54a91a2d78e3798e5b2ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80a9232c8f2e4618b25cad1445dfdc70",
            "placeholder": "​",
            "style": "IPY_MODEL_f7fba1b83e2842f2b2e2074687aead4e",
            "value": "tokenizer.json: "
          }
        },
        "2adad6653a954973a7ca80cf80943c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17c1be419e764c8bbb375c139cbd5be4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d9f2fe4958b486c9c83518eaa4b2f75",
            "value": 1
          }
        },
        "1a9ccea166cb4aa0bf51a9426c3cac28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e71a6e547fc54b0b83955c3c2f27b45b",
            "placeholder": "​",
            "style": "IPY_MODEL_0ca1c035812c49f3aa90f3ef8cd309e2",
            "value": " 1.39M/? [00:00&lt;00:00, 26.6MB/s]"
          }
        },
        "291c5b112577479c8c0aa12c7fcf065d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80a9232c8f2e4618b25cad1445dfdc70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7fba1b83e2842f2b2e2074687aead4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17c1be419e764c8bbb375c139cbd5be4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4d9f2fe4958b486c9c83518eaa4b2f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e71a6e547fc54b0b83955c3c2f27b45b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ca1c035812c49f3aa90f3ef8cd309e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "208c94eade1644a582bae703aabb495c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_842815ea79ec4847bea59057d6cc7b21",
              "IPY_MODEL_2c15b72eb6ec4f0897035d26c181444f",
              "IPY_MODEL_ea3ef4d9226d43de8b9cd512ebf06052"
            ],
            "layout": "IPY_MODEL_3dca8268bace4c979359c1a2395e50ee"
          }
        },
        "842815ea79ec4847bea59057d6cc7b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_294f84fb905448f794fbc131f73b7b81",
            "placeholder": "​",
            "style": "IPY_MODEL_ca9057bee3784791805d0ee672bf34e9",
            "value": "model.safetensors: 100%"
          }
        },
        "2c15b72eb6ec4f0897035d26c181444f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_110ca3d1e02d4ec2ab38d47e8d8ef900",
            "max": 891646390,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ffc8d765a6c443fbaa9cae3c35f4758",
            "value": 891646390
          }
        },
        "ea3ef4d9226d43de8b9cd512ebf06052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_095bf3c65274404bb1b5c7d9d565a6ac",
            "placeholder": "​",
            "style": "IPY_MODEL_edae78ee811b41c8a3f44c5c333dfe7d",
            "value": " 892M/892M [00:23&lt;00:00, 45.1MB/s]"
          }
        },
        "3dca8268bace4c979359c1a2395e50ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "294f84fb905448f794fbc131f73b7b81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca9057bee3784791805d0ee672bf34e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "110ca3d1e02d4ec2ab38d47e8d8ef900": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ffc8d765a6c443fbaa9cae3c35f4758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "095bf3c65274404bb1b5c7d9d565a6ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edae78ee811b41c8a3f44c5c333dfe7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "820449386d43425e952aa6094e4fff65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80e544ae95184e6aba8430f608d35f4a",
              "IPY_MODEL_c0976e1d10ac4328a28e85da7f319de2",
              "IPY_MODEL_a3b865f448254fedad2f1c08f4038ae5"
            ],
            "layout": "IPY_MODEL_7897df3dfd014af782e6cc591f9cd8c0"
          }
        },
        "80e544ae95184e6aba8430f608d35f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_514285525d0b4f52924f9cbf06f6ef9f",
            "placeholder": "​",
            "style": "IPY_MODEL_f8f9c711447447e8b13061be50bf4cbe",
            "value": "generation_config.json: 100%"
          }
        },
        "c0976e1d10ac4328a28e85da7f319de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_781c5f6eac144774a3edf2072b796031",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e58dc0cce434e638a835430ed47cf12",
            "value": 147
          }
        },
        "a3b865f448254fedad2f1c08f4038ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48d363794e9a45ceb8d6fa5fe1a2cdaf",
            "placeholder": "​",
            "style": "IPY_MODEL_b41daeebbb7546c6986db5ceb7ed3fe5",
            "value": " 147/147 [00:00&lt;00:00, 13.2kB/s]"
          }
        },
        "7897df3dfd014af782e6cc591f9cd8c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "514285525d0b4f52924f9cbf06f6ef9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8f9c711447447e8b13061be50bf4cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "781c5f6eac144774a3edf2072b796031": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e58dc0cce434e638a835430ed47cf12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48d363794e9a45ceb8d6fa5fe1a2cdaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b41daeebbb7546c6986db5ceb7ed3fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}